{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network-based Gene Prioritization from GWAS Data\n",
    "MED283: Network Biology & Biomedicine  \n",
    "Nadia Arang & Kevin Chau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import ndex2\n",
    "import networkx as nx\n",
    "from networkx.algorithms import community\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pcnet from server\n",
    "pc_nice = ndex2.create_nice_cx_from_server(server = \"http://public.ndexbio.org\", \n",
    "                                           uuid = \"f93f402c-86d4-11e7-a10d-0ac135e8bacf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast as networkx object\n",
    "# First cast to pandas since networkx 2.1 is incompatible with ndex2\n",
    "pc_pd = pc_nice.to_pandas_dataframe()\n",
    "pcnet = nx.from_pandas_edgelist(pc_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load significance values for snps\n",
    "snps = {_[0]: _[8] \n",
    "        for _ in [line.strip().split() \n",
    "                  for line in open(\"../src/snp_level_summary_stats_pmid_25056061.txt\", \"r\").readlines()[1:]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rudimentary gene scoring by # snps normalized by gene length\n",
    "genes_score = {_[1]: {\"Score\": [(int(_[5]) / (int(_[4]) - int(_[3])))]}\n",
    "               for _ in [line.strip().split() \n",
    "                         for line in open(\"../src/gene_level_summary_stats_pmid_25056061.txt\", \"r\").readlines()[1:]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gene level p-value\n",
    "genes_p = {_[1]: {\"Pvalue\": float(_[8])} \n",
    "          for _ in [line.strip().split() \n",
    "                    for line in open(\"../src/gene_level_summary_stats_pmid_25056061.txt\", \"r\").readlines()[1:]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HIST1H4K': {'Pvalue': 5.07118e-10},\n",
       " 'HIST1H2AK': {'Pvalue': 5.07118e-10},\n",
       " 'HIST1H2BN': {'Pvalue': 5.07118e-10},\n",
       " 'HIST1H2AL': {'Pvalue': 7.05379e-10},\n",
       " 'HIST1H1B': {'Pvalue': 7.05379e-10},\n",
       " 'HIST1H3I': {'Pvalue': 7.05379e-10},\n",
       " 'HIST1H4L': {'Pvalue': 7.05379e-10},\n",
       " 'PGBD1': {'Pvalue': 1.23604e-09},\n",
       " 'HIST1H1E': {'Pvalue': 1.4581e-09},\n",
       " 'HIST1H2BD': {'Pvalue': 1.4581e-09},\n",
       " 'ZKSCAN4': {'Pvalue': 1.79494e-09},\n",
       " 'ZSCAN12': {'Pvalue': 1.98264e-09},\n",
       " 'ZNF165': {'Pvalue': 4.12863e-09},\n",
       " 'NKAPL': {'Pvalue': 5.03498e-09},\n",
       " 'OR2B2': {'Pvalue': 1.02055e-08},\n",
       " 'NT5C2': {'Pvalue': 2.2317e-08},\n",
       " 'ZSCAN23': {'Pvalue': 2.70701e-08},\n",
       " 'EI24': {'Pvalue': 2.91065e-08},\n",
       " 'ZNF184': {'Pvalue': 4.02935e-08},\n",
       " 'ZKSCAN3': {'Pvalue': 4.75173e-08},\n",
       " 'MAD1L1': {'Pvalue': 5.06103e-08},\n",
       " 'CNNM2': {'Pvalue': 6.39413e-08},\n",
       " 'AS3MT': {'Pvalue': 1.30103e-07},\n",
       " 'STT3A': {'Pvalue': 1.50685e-07},\n",
       " 'CHEK1': {'Pvalue': 1.79376e-07},\n",
       " 'HIST1H2BL': {'Pvalue': 2.41439e-07},\n",
       " 'HIST1H3H': {'Pvalue': 2.41439e-07},\n",
       " 'HIST1H2AJ': {'Pvalue': 2.41439e-07},\n",
       " 'HIST1H2BM': {'Pvalue': 2.41439e-07},\n",
       " 'PATE1': {'Pvalue': 2.61283e-07},\n",
       " 'SCGN': {'Pvalue': 3.01973e-07},\n",
       " 'SLC17A1': {'Pvalue': 3.07583e-07},\n",
       " 'HIST1H4J': {'Pvalue': 3.42184e-07},\n",
       " 'PLCB2': {'Pvalue': 3.49022e-07},\n",
       " 'HIST1H2BC': {'Pvalue': 3.6608e-07},\n",
       " 'HIST1H2AC': {'Pvalue': 3.6608e-07},\n",
       " 'SLC17A3': {'Pvalue': 4.00306e-07},\n",
       " 'BTN3A2': {'Pvalue': 4.75563e-07},\n",
       " 'BTN2A2': {'Pvalue': 4.75563e-07},\n",
       " 'BTN2A1': {'Pvalue': 4.7653e-07},\n",
       " 'HIST1H1T': {'Pvalue': 4.82895e-07},\n",
       " 'HFE': {'Pvalue': 4.87945e-07},\n",
       " 'HIST1H4C': {'Pvalue': 4.87945e-07},\n",
       " 'SLC17A4': {'Pvalue': 5.21401e-07},\n",
       " 'TCF4': {'Pvalue': 5.5784e-07},\n",
       " 'GPX5': {'Pvalue': 6.14258e-07},\n",
       " 'AK3': {'Pvalue': 6.5734e-07},\n",
       " 'PRSS16': {'Pvalue': 8.95776e-07},\n",
       " 'NUDT1': {'Pvalue': 1.14743e-06},\n",
       " 'SNX8': {'Pvalue': 1.14743e-06},\n",
       " 'CCDC39': {'Pvalue': 1.27238e-06},\n",
       " 'HIST1H2BJ': {'Pvalue': 1.54105e-06},\n",
       " 'HIST1H2AG': {'Pvalue': 1.54105e-06},\n",
       " 'PKNOX2': {'Pvalue': 1.83862e-06},\n",
       " 'PIK3C2A': {'Pvalue': 1.90475e-06},\n",
       " 'HIST1H3C': {'Pvalue': 1.97631e-06},\n",
       " 'HIST1H1C': {'Pvalue': 1.97631e-06},\n",
       " 'BTN1A1': {'Pvalue': 2.08221e-06},\n",
       " 'CUL9': {'Pvalue': 2.14645e-06},\n",
       " 'ITIH4': {'Pvalue': 2.25023e-06},\n",
       " 'MUSTN1': {'Pvalue': 3.21402e-06},\n",
       " 'HLA-DRB5': {'Pvalue': 3.33618e-06},\n",
       " 'ITIH3': {'Pvalue': 3.64782e-06},\n",
       " 'SDCCAG8': {'Pvalue': 3.80599e-06},\n",
       " 'AGBL3': {'Pvalue': 4.17951e-06},\n",
       " 'LY6G6F': {'Pvalue': 4.25419e-06},\n",
       " 'TCP10L': {'Pvalue': 5.0169e-06},\n",
       " 'CALN1': {'Pvalue': 5.1597e-06},\n",
       " 'NGEF': {'Pvalue': 5.30692e-06},\n",
       " 'MFHAS1': {'Pvalue': 5.78097e-06},\n",
       " 'DPYD': {'Pvalue': 5.95415e-06},\n",
       " 'ITIH1': {'Pvalue': 6.01657e-06},\n",
       " 'MMP16': {'Pvalue': 6.46334e-06},\n",
       " 'FEZ1': {'Pvalue': 6.81077e-06},\n",
       " 'HIST1H1A': {'Pvalue': 6.91819e-06},\n",
       " 'HIST1H3A': {'Pvalue': 6.91819e-06},\n",
       " 'HIST1H4A': {'Pvalue': 6.91819e-06},\n",
       " 'HIST1H4B': {'Pvalue': 6.91819e-06},\n",
       " 'HIST1H3B': {'Pvalue': 6.91819e-06},\n",
       " 'IFT172': {'Pvalue': 7.05264e-06},\n",
       " 'FNDC4': {'Pvalue': 7.05264e-06},\n",
       " 'NTRK3': {'Pvalue': 7.49055e-06},\n",
       " 'APP': {'Pvalue': 9.56008e-06},\n",
       " 'TXNRD2': {'Pvalue': 9.66733e-06},\n",
       " 'BANK1': {'Pvalue': 1.09975e-05},\n",
       " 'SRF': {'Pvalue': 1.12466e-05},\n",
       " 'BTNL2': {'Pvalue': 1.13368e-05},\n",
       " 'HMGN4': {'Pvalue': 1.19156e-05},\n",
       " 'GGA3': {'Pvalue': 1.29919e-05},\n",
       " 'GIGYF2': {'Pvalue': 1.4548e-05},\n",
       " 'CDH12': {'Pvalue': 1.48482e-05},\n",
       " 'HIST1H2AB': {'Pvalue': 1.49112e-05},\n",
       " 'LUZP2': {'Pvalue': 1.5792e-05},\n",
       " 'FOXN2': {'Pvalue': 1.63829e-05},\n",
       " 'CTNND1': {'Pvalue': 1.66368e-05},\n",
       " 'TMEM132E': {'Pvalue': 1.73776e-05},\n",
       " 'PSD3': {'Pvalue': 1.74622e-05},\n",
       " 'TRIM38': {'Pvalue': 1.74867e-05},\n",
       " 'BTN3A1': {'Pvalue': 1.87099e-05},\n",
       " 'CREB3L1': {'Pvalue': 1.88424e-05},\n",
       " 'TMX2': {'Pvalue': 1.93306e-05},\n",
       " 'SFMBT1': {'Pvalue': 1.9668e-05},\n",
       " 'KIAA0391': {'Pvalue': 2.02163e-05},\n",
       " 'SLCO4C1': {'Pvalue': 2.07758e-05},\n",
       " 'CWF19L2': {'Pvalue': 2.07998e-05},\n",
       " 'GCKR': {'Pvalue': 2.19126e-05},\n",
       " 'CLP1': {'Pvalue': 2.19559e-05},\n",
       " 'VRK2': {'Pvalue': 2.62847e-05},\n",
       " 'FANCL': {'Pvalue': 2.62847e-05},\n",
       " 'ZDHHC5': {'Pvalue': 2.75731e-05},\n",
       " 'MED19': {'Pvalue': 2.75731e-05},\n",
       " 'WDR18': {'Pvalue': 2.98405e-05},\n",
       " 'GRIN3B': {'Pvalue': 2.98405e-05},\n",
       " 'DPF3': {'Pvalue': 3.00115e-05},\n",
       " 'GRM3': {'Pvalue': 3.18347e-05},\n",
       " 'MAGOH': {'Pvalue': 3.22838e-05},\n",
       " 'LRP8': {'Pvalue': 3.22838e-05},\n",
       " 'PROX2': {'Pvalue': 3.23994e-05},\n",
       " 'ZDHHC2': {'Pvalue': 3.25772e-05},\n",
       " 'ZSCAN20': {'Pvalue': 3.27926e-05},\n",
       " 'SERPINF2': {'Pvalue': 3.33966e-05},\n",
       " 'SERPINF1': {'Pvalue': 3.33966e-05},\n",
       " 'VPS37A': {'Pvalue': 3.40951e-05},\n",
       " 'DNAJC19': {'Pvalue': 3.42759e-05},\n",
       " 'YPEL4': {'Pvalue': 3.44811e-05},\n",
       " 'CALHM1': {'Pvalue': 3.58144e-05},\n",
       " 'CALHM3': {'Pvalue': 3.58144e-05},\n",
       " 'ABT1': {'Pvalue': 3.5904e-05},\n",
       " 'EMX1': {'Pvalue': 3.68433e-05},\n",
       " 'TMEM151B': {'Pvalue': 3.78752e-05},\n",
       " 'SPATS1': {'Pvalue': 3.78752e-05},\n",
       " 'DNAJA3': {'Pvalue': 3.85105e-05},\n",
       " 'NMRAL1': {'Pvalue': 3.85105e-05},\n",
       " 'HMOX2': {'Pvalue': 3.99761e-05},\n",
       " 'FOXP1': {'Pvalue': 4.24299e-05},\n",
       " 'INHBA': {'Pvalue': 4.36891e-05},\n",
       " 'KIF5C': {'Pvalue': 4.44872e-05},\n",
       " 'SNX19': {'Pvalue': 4.472e-05},\n",
       " 'FAM120AOS': {'Pvalue': 4.48738e-05},\n",
       " 'RRP12': {'Pvalue': 4.53126e-05},\n",
       " 'HIST1H3J': {'Pvalue': 4.55229e-05},\n",
       " 'MYLK4': {'Pvalue': 4.57597e-05},\n",
       " 'CDC5L': {'Pvalue': 4.73225e-05},\n",
       " 'FEZF1': {'Pvalue': 4.77657e-05},\n",
       " 'THRB': {'Pvalue': 4.85733e-05},\n",
       " 'FXR1': {'Pvalue': 4.94019e-05},\n",
       " 'ZSWIM4': {'Pvalue': 4.98282e-05},\n",
       " 'TTC23': {'Pvalue': 5.05169e-05},\n",
       " 'SLFN5': {'Pvalue': 5.18921e-05},\n",
       " 'DIP2B': {'Pvalue': 5.29084e-05},\n",
       " 'UNC5B': {'Pvalue': 5.2978e-05},\n",
       " 'KATNAL2': {'Pvalue': 5.4818e-05},\n",
       " 'HIST1H2AM': {'Pvalue': 5.5074e-05},\n",
       " 'HIST1H2BO': {'Pvalue': 5.5074e-05},\n",
       " 'SUFU': {'Pvalue': 5.56403e-05},\n",
       " 'CADPS2': {'Pvalue': 5.5958e-05},\n",
       " 'XPR1': {'Pvalue': 5.62082e-05},\n",
       " 'UBE2D2': {'Pvalue': 5.7539e-05},\n",
       " 'LRP5': {'Pvalue': 5.76315e-05},\n",
       " 'SFXN2': {'Pvalue': 5.76985e-05},\n",
       " 'PTBP2': {'Pvalue': 5.79765e-05},\n",
       " 'NCAN': {'Pvalue': 5.84525e-05},\n",
       " 'HAPLN4': {'Pvalue': 5.84525e-05},\n",
       " 'ARL3': {'Pvalue': 6.04486e-05},\n",
       " 'RIMS1': {'Pvalue': 6.18555e-05},\n",
       " 'SLC9A9': {'Pvalue': 6.33503e-05},\n",
       " 'SLC17A2': {'Pvalue': 6.37545e-05},\n",
       " 'SPOCK1': {'Pvalue': 6.43794e-05},\n",
       " 'GNL3': {'Pvalue': 6.5992e-05},\n",
       " 'GLT8D1': {'Pvalue': 6.5992e-05},\n",
       " 'GLDC': {'Pvalue': 6.73596e-05},\n",
       " 'PBRM1': {'Pvalue': 7.00493e-05},\n",
       " 'TRIM8': {'Pvalue': 7.01323e-05},\n",
       " 'CDH13': {'Pvalue': 7.04122e-05},\n",
       " 'SLCO6A1': {'Pvalue': 7.10341e-05},\n",
       " 'XYLB': {'Pvalue': 7.25904e-05},\n",
       " 'CYP2C9': {'Pvalue': 7.3608e-05},\n",
       " 'AKT3': {'Pvalue': 7.3873e-05},\n",
       " 'HIST1H2BK': {'Pvalue': 7.52089e-05},\n",
       " 'HIST1H2AH': {'Pvalue': 7.52089e-05},\n",
       " 'CYP17A1': {'Pvalue': 7.6039e-05},\n",
       " 'MC3R': {'Pvalue': 7.61104e-05},\n",
       " 'HIST1H4I': {'Pvalue': 7.75665e-05},\n",
       " 'SLC4A10': {'Pvalue': 7.98598e-05},\n",
       " 'KLHL1': {'Pvalue': 8.16713e-05},\n",
       " 'TBC1D12': {'Pvalue': 8.21119e-05},\n",
       " 'SH3GL3': {'Pvalue': 8.44609e-05},\n",
       " 'CORO7': {'Pvalue': 8.6508e-05},\n",
       " 'ACOXL': {'Pvalue': 8.91435e-05},\n",
       " 'SGSM1': {'Pvalue': 9.21929e-05},\n",
       " 'NEK4': {'Pvalue': 9.49522e-05},\n",
       " 'SPCS1': {'Pvalue': 9.63855e-05},\n",
       " 'TTC31': {'Pvalue': 9.76535e-05},\n",
       " 'LBX2': {'Pvalue': 9.76535e-05},\n",
       " 'PCGF1': {'Pvalue': 9.76535e-05},\n",
       " 'SRPK2': {'Pvalue': 9.80922e-05},\n",
       " 'ART3': {'Pvalue': 0.000100463},\n",
       " 'EIF4E2': {'Pvalue': 0.000100582},\n",
       " 'ZBED4': {'Pvalue': 0.000101288},\n",
       " 'WDR73': {'Pvalue': 0.000101328},\n",
       " 'NMB': {'Pvalue': 0.000101328},\n",
       " 'PLA2G2F': {'Pvalue': 0.000101447},\n",
       " 'KCNQ3': {'Pvalue': 0.000101969},\n",
       " 'OSBPL1A': {'Pvalue': 0.000103142},\n",
       " 'HEBP1': {'Pvalue': 0.00010325},\n",
       " 'C12orf42': {'Pvalue': 0.000104417},\n",
       " 'ANP32E': {'Pvalue': 0.000105115},\n",
       " 'DCP1B': {'Pvalue': 0.000105597},\n",
       " 'TMEM173': {'Pvalue': 0.000106332},\n",
       " 'FOXR1': {'Pvalue': 0.000108942},\n",
       " 'GLG1': {'Pvalue': 0.000109326},\n",
       " 'CA14': {'Pvalue': 0.000109398},\n",
       " 'APH1A': {'Pvalue': 0.000109398},\n",
       " 'C1orf54': {'Pvalue': 0.000109398},\n",
       " 'PRPF3': {'Pvalue': 0.000109489},\n",
       " 'NLN': {'Pvalue': 0.000110833},\n",
       " 'FHIT': {'Pvalue': 0.000111057},\n",
       " 'OR1Q1': {'Pvalue': 0.000111064},\n",
       " 'OR1B1': {'Pvalue': 0.000111064},\n",
       " 'PPM1M': {'Pvalue': 0.000111364},\n",
       " 'WDR82': {'Pvalue': 0.000111364},\n",
       " 'DPEP1': {'Pvalue': 0.000111406},\n",
       " 'TTC7B': {'Pvalue': 0.000111456},\n",
       " 'CTNNA1': {'Pvalue': 0.000111655},\n",
       " 'TCERG1L': {'Pvalue': 0.000112261},\n",
       " 'CYP2C19': {'Pvalue': 0.000112316},\n",
       " 'SH3PXD2A': {'Pvalue': 0.000113348},\n",
       " 'PDCD11': {'Pvalue': 0.000114966},\n",
       " 'CALHM2': {'Pvalue': 0.000114966},\n",
       " 'ALG12': {'Pvalue': 0.000116322},\n",
       " 'PCDH8': {'Pvalue': 0.000117956},\n",
       " 'PTK7': {'Pvalue': 0.000118776},\n",
       " 'RPRD2': {'Pvalue': 0.000118818},\n",
       " 'BRD1': {'Pvalue': 0.000119461},\n",
       " 'MDGA2': {'Pvalue': 0.000119947},\n",
       " 'TWF2': {'Pvalue': 0.000121545},\n",
       " 'FAM184A': {'Pvalue': 0.000121588},\n",
       " 'CAMK1D': {'Pvalue': 0.000124069},\n",
       " 'KCNG1': {'Pvalue': 0.000124599},\n",
       " 'HELLS': {'Pvalue': 0.000126734},\n",
       " 'CXXC5': {'Pvalue': 0.000128018},\n",
       " 'PRDM14': {'Pvalue': 0.000128225},\n",
       " 'UPK2': {'Pvalue': 0.000131917},\n",
       " 'ZNF423': {'Pvalue': 0.000136227},\n",
       " 'KCNQ1': {'Pvalue': 0.000137315},\n",
       " 'PIAS2': {'Pvalue': 0.000137583},\n",
       " 'SIL1': {'Pvalue': 0.000139118},\n",
       " 'VPS41': {'Pvalue': 0.000139849},\n",
       " 'CNOT7': {'Pvalue': 0.000141203},\n",
       " 'ANTXR1': {'Pvalue': 0.000141428},\n",
       " 'PBX1': {'Pvalue': 0.000141602},\n",
       " 'FAM120A': {'Pvalue': 0.000142495},\n",
       " 'QPCT': {'Pvalue': 0.000142849},\n",
       " 'TRIM24': {'Pvalue': 0.00014457},\n",
       " 'SVOPL': {'Pvalue': 0.00014457},\n",
       " 'RFT1': {'Pvalue': 0.000145932},\n",
       " 'POMT1': {'Pvalue': 0.000146087},\n",
       " 'CDH4': {'Pvalue': 0.000152043},\n",
       " 'BNIP2': {'Pvalue': 0.00015268},\n",
       " 'MRPS21': {'Pvalue': 0.000153055},\n",
       " 'CPEB1': {'Pvalue': 0.000154597},\n",
       " 'NRBP1': {'Pvalue': 0.000157651},\n",
       " 'KRTCAP3': {'Pvalue': 0.000157651},\n",
       " 'TTLL6': {'Pvalue': 0.000157662},\n",
       " 'SORBS2': {'Pvalue': 0.000158491},\n",
       " 'LPAR3': {'Pvalue': 0.000161304},\n",
       " 'PRR12': {'Pvalue': 0.000161344},\n",
       " 'LYN': {'Pvalue': 0.000163127},\n",
       " 'MTMR7': {'Pvalue': 0.000167993},\n",
       " 'LIPC': {'Pvalue': 0.000168139},\n",
       " 'PTPRM': {'Pvalue': 0.000169059},\n",
       " 'LIMA1': {'Pvalue': 0.000169637},\n",
       " 'CLSTN2': {'Pvalue': 0.000169971},\n",
       " 'NDUFA13': {'Pvalue': 0.000170491},\n",
       " 'YJEFN3': {'Pvalue': 0.000170491},\n",
       " 'CILP2': {'Pvalue': 0.000170491},\n",
       " 'TMEM211': {'Pvalue': 0.000171608},\n",
       " 'ZNF835': {'Pvalue': 0.000173176},\n",
       " 'MAN1A1': {'Pvalue': 0.000174655},\n",
       " 'STAG1': {'Pvalue': 0.000181359},\n",
       " 'CREB5': {'Pvalue': 0.000181946},\n",
       " 'STK31': {'Pvalue': 0.000182452},\n",
       " 'RYR2': {'Pvalue': 0.000183259},\n",
       " 'NUP54': {'Pvalue': 0.000184045},\n",
       " 'ZNF804A': {'Pvalue': 0.000184219},\n",
       " 'SYNM': {'Pvalue': 0.000186197},\n",
       " 'SNRK': {'Pvalue': 0.000187873},\n",
       " 'PGAM1': {'Pvalue': 0.000189038},\n",
       " 'KCNAB2': {'Pvalue': 0.000189115},\n",
       " 'AP3B2': {'Pvalue': 0.000190972},\n",
       " 'SLC25A21': {'Pvalue': 0.000191867},\n",
       " 'TSSK6': {'Pvalue': 0.000191996},\n",
       " 'CACNA1A': {'Pvalue': 0.000192315},\n",
       " 'SLC32A1': {'Pvalue': 0.000193313},\n",
       " 'C16orf91': {'Pvalue': 0.000193564},\n",
       " 'CCDC154': {'Pvalue': 0.000193564},\n",
       " 'CTF1': {'Pvalue': 0.000193623},\n",
       " 'KIF26B': {'Pvalue': 0.000194021},\n",
       " 'DDX24': {'Pvalue': 0.000194309},\n",
       " 'IFI27L1': {'Pvalue': 0.000194309},\n",
       " 'ADAMTS2': {'Pvalue': 0.000194836},\n",
       " 'ANKS6': {'Pvalue': 0.000196708},\n",
       " 'CRELD2': {'Pvalue': 0.000200301},\n",
       " 'ADRA1D': {'Pvalue': 0.000201856},\n",
       " 'TSNARE1': {'Pvalue': 0.000203826},\n",
       " 'NRG2': {'Pvalue': 0.000207573},\n",
       " 'TMCO5A': {'Pvalue': 0.000209071},\n",
       " 'RFWD3': {'Pvalue': 0.000210798},\n",
       " 'ZSCAN2': {'Pvalue': 0.000211047},\n",
       " 'KCNK9': {'Pvalue': 0.000211597},\n",
       " 'SPP2': {'Pvalue': 0.000213828},\n",
       " 'STX18': {'Pvalue': 0.000214104},\n",
       " 'ADAMTS17': {'Pvalue': 0.000214591},\n",
       " 'DGKI': {'Pvalue': 0.000217467},\n",
       " 'NOS2': {'Pvalue': 0.000218148},\n",
       " 'TIGD1': {'Pvalue': 0.000219375},\n",
       " 'ASB3': {'Pvalue': 0.000222959},\n",
       " 'C8orf37': {'Pvalue': 0.00022421},\n",
       " 'GLI3': {'Pvalue': 0.000224255},\n",
       " 'OPCML': {'Pvalue': 0.000230006},\n",
       " 'ZNF385A': {'Pvalue': 0.000230199},\n",
       " 'LDB2': {'Pvalue': 0.000233015},\n",
       " 'SIRPG': {'Pvalue': 0.000233559},\n",
       " 'CMTM8': {'Pvalue': 0.000234382},\n",
       " 'NPHP4': {'Pvalue': 0.000237758},\n",
       " 'GTF3C2': {'Pvalue': 0.000238976},\n",
       " 'EIF2B4': {'Pvalue': 0.000238976},\n",
       " 'SNX17': {'Pvalue': 0.000238976},\n",
       " 'EXOSC1': {'Pvalue': 0.000248149},\n",
       " 'ZDHHC16': {'Pvalue': 0.000248149},\n",
       " 'PCDH15': {'Pvalue': 0.000253308},\n",
       " 'CCDC85A': {'Pvalue': 0.000254474},\n",
       " 'ADIPOR2': {'Pvalue': 0.000254965},\n",
       " 'GPC1': {'Pvalue': 0.000259828},\n",
       " 'GATAD2A': {'Pvalue': 0.000262528},\n",
       " 'PHF7': {'Pvalue': 0.000263017},\n",
       " 'CCDC122': {'Pvalue': 0.000264017},\n",
       " 'PBX4': {'Pvalue': 0.000265202},\n",
       " 'TYK2': {'Pvalue': 0.000265447},\n",
       " 'SPTLC1': {'Pvalue': 0.000268212},\n",
       " 'RTN1': {'Pvalue': 0.000269326},\n",
       " 'DHX34': {'Pvalue': 0.000272419},\n",
       " 'LRP1B': {'Pvalue': 0.000272504},\n",
       " 'CHRNA3': {'Pvalue': 0.000273966},\n",
       " 'ASAP1': {'Pvalue': 0.000274919},\n",
       " 'GRIA1': {'Pvalue': 0.000275084},\n",
       " 'SLTM': {'Pvalue': 0.00027664},\n",
       " 'PPM1G': {'Pvalue': 0.000279752},\n",
       " 'ZNF513': {'Pvalue': 0.000281016},\n",
       " 'BAP1': {'Pvalue': 0.000281875},\n",
       " 'IMMP2L': {'Pvalue': 0.000282486},\n",
       " 'CROT': {'Pvalue': 0.000285},\n",
       " 'SLC25A23': {'Pvalue': 0.000287099},\n",
       " 'CRB3': {'Pvalue': 0.000287099},\n",
       " 'GPC6': {'Pvalue': 0.000288758},\n",
       " 'ALAS1': {'Pvalue': 0.00028976},\n",
       " 'SPHKAP': {'Pvalue': 0.000291213},\n",
       " 'HIST1H2AA': {'Pvalue': 0.000292223},\n",
       " 'HIST1H2BA': {'Pvalue': 0.000292223},\n",
       " 'HIST1H2BE': {'Pvalue': 0.000293657},\n",
       " 'MSRA': {'Pvalue': 0.000294658},\n",
       " 'RPS6KA2': {'Pvalue': 0.000294989},\n",
       " 'FSTL4': {'Pvalue': 0.000296919},\n",
       " 'ULBP3': {'Pvalue': 0.000298496},\n",
       " 'RPRD1A': {'Pvalue': 0.000299255},\n",
       " 'APBA1': {'Pvalue': 0.000300351},\n",
       " 'PLEKHO1': {'Pvalue': 0.000302045},\n",
       " 'L3MBTL2': {'Pvalue': 0.00030735},\n",
       " 'CHADL': {'Pvalue': 0.00030735},\n",
       " 'GALNT3': {'Pvalue': 0.000308102},\n",
       " 'TM6SF2': {'Pvalue': 0.000309564},\n",
       " 'NISCH': {'Pvalue': 0.000309581},\n",
       " 'TMEM132D': {'Pvalue': 0.000313502},\n",
       " 'MPV17': {'Pvalue': 0.000314212},\n",
       " 'HIST1H4H': {'Pvalue': 0.000318042},\n",
       " 'C18orf21': {'Pvalue': 0.000318624},\n",
       " 'GUCY1A2': {'Pvalue': 0.000319206},\n",
       " 'NAB2': {'Pvalue': 0.00032447},\n",
       " 'STAT6': {'Pvalue': 0.00032447},\n",
       " 'DENND1C': {'Pvalue': 0.000324977},\n",
       " 'MANEAL': {'Pvalue': 0.00032855},\n",
       " 'ROR2': {'Pvalue': 0.000328911},\n",
       " 'TLR9': {'Pvalue': 0.000329325},\n",
       " 'NOSIP': {'Pvalue': 0.000329929},\n",
       " 'B3GAT2': {'Pvalue': 0.00033002},\n",
       " 'NUP50': {'Pvalue': 0.00033003},\n",
       " 'KCNAB1': {'Pvalue': 0.000332907},\n",
       " 'RAF1': {'Pvalue': 0.000335215},\n",
       " 'RERE': {'Pvalue': 0.000336492},\n",
       " 'CHAC2': {'Pvalue': 0.000336588},\n",
       " 'SETBP1': {'Pvalue': 0.00033709},\n",
       " 'MBD5': {'Pvalue': 0.000339367},\n",
       " 'UCK1': {'Pvalue': 0.000342278},\n",
       " 'UBR3': {'Pvalue': 0.000344252},\n",
       " 'MYH13': {'Pvalue': 0.000344564},\n",
       " 'PRKD3': {'Pvalue': 0.00034829},\n",
       " 'CHMP1A': {'Pvalue': 0.000348529},\n",
       " 'ABCG2': {'Pvalue': 0.000350814},\n",
       " 'ALDH5A1': {'Pvalue': 0.000353275},\n",
       " 'BNC2': {'Pvalue': 0.000355352},\n",
       " 'ELL': {'Pvalue': 0.000356701},\n",
       " 'FKBP8': {'Pvalue': 0.000356701},\n",
       " 'PPP2R3A': {'Pvalue': 0.000359499},\n",
       " 'ABCC10': {'Pvalue': 0.000360346},\n",
       " 'PLAA': {'Pvalue': 0.000360963},\n",
       " 'CPA5': {'Pvalue': 0.000363203},\n",
       " 'CPA4': {'Pvalue': 0.000365356},\n",
       " 'KIAA0513': {'Pvalue': 0.000365673},\n",
       " 'CACNA1I': {'Pvalue': 0.000367343},\n",
       " 'NPL': {'Pvalue': 0.000367432},\n",
       " 'PRC1': {'Pvalue': 0.000367781},\n",
       " 'VPS33B': {'Pvalue': 0.000367781},\n",
       " 'PPP1R16B': {'Pvalue': 0.000368709},\n",
       " 'TACC2': {'Pvalue': 0.00036892},\n",
       " 'BTN3A3': {'Pvalue': 0.000369249},\n",
       " 'C21orf91': {'Pvalue': 0.000375654},\n",
       " 'NPAS3': {'Pvalue': 0.000376603},\n",
       " 'CHRNA5': {'Pvalue': 0.000377101},\n",
       " 'SLC29A1': {'Pvalue': 0.000379038},\n",
       " 'CD46': {'Pvalue': 0.000380626},\n",
       " 'ANO2': {'Pvalue': 0.00038304},\n",
       " 'PRRG2': {'Pvalue': 0.000383909},\n",
       " 'HPSE': {'Pvalue': 0.000385143},\n",
       " 'OSBPL10': {'Pvalue': 0.000387595},\n",
       " 'ATP6V0D2': {'Pvalue': 0.00039117},\n",
       " 'ACTR5': {'Pvalue': 0.000391246},\n",
       " 'NXNL2': {'Pvalue': 0.0003975},\n",
       " 'TOP3B': {'Pvalue': 0.000406495},\n",
       " 'SNX25': {'Pvalue': 0.00040789},\n",
       " 'YRDC': {'Pvalue': 0.000408748},\n",
       " 'C1orf122': {'Pvalue': 0.000408748},\n",
       " 'HCLS1': {'Pvalue': 0.000412374},\n",
       " 'ANKRD42': {'Pvalue': 0.000413194},\n",
       " 'PPM1F': {'Pvalue': 0.000414652},\n",
       " 'DNAJC18': {'Pvalue': 0.000414907},\n",
       " 'EIF2AK2': {'Pvalue': 0.000425759},\n",
       " 'GPM6A': {'Pvalue': 0.000430732},\n",
       " 'ZDHHC18': {'Pvalue': 0.000434125},\n",
       " 'EXT1': {'Pvalue': 0.000434193},\n",
       " 'ZBTB16': {'Pvalue': 0.000435356},\n",
       " 'MRRF': {'Pvalue': 0.000435745},\n",
       " 'SYNJ1': {'Pvalue': 0.000436053},\n",
       " 'SLC6A6': {'Pvalue': 0.000436813},\n",
       " 'SEC11A': {'Pvalue': 0.000437076},\n",
       " 'CCDC90B': {'Pvalue': 0.000437356},\n",
       " 'ACTR8': {'Pvalue': 0.000437637},\n",
       " 'TSPAN2': {'Pvalue': 0.000446718},\n",
       " 'DPP4': {'Pvalue': 0.000451983},\n",
       " 'MTF1': {'Pvalue': 0.000455289},\n",
       " 'SGCZ': {'Pvalue': 0.000456399},\n",
       " 'FBXO40': {'Pvalue': 0.000457538},\n",
       " 'NT5DC2': {'Pvalue': 0.000463541},\n",
       " 'WWOX': {'Pvalue': 0.000464551},\n",
       " 'PDIA3': {'Pvalue': 0.000467226},\n",
       " 'ELL3': {'Pvalue': 0.000467226},\n",
       " 'SEMA4F': {'Pvalue': 0.00047259},\n",
       " 'VPS45': {'Pvalue': 0.000473618},\n",
       " 'CARS2': {'Pvalue': 0.000486278},\n",
       " 'ING1': {'Pvalue': 0.000486278},\n",
       " 'WDR88': {'Pvalue': 0.000487582},\n",
       " 'SIRPB1': {'Pvalue': 0.000487975},\n",
       " 'ERC1': {'Pvalue': 0.000490014},\n",
       " 'CCDC15': {'Pvalue': 0.00049042},\n",
       " 'GTF2A2': {'Pvalue': 0.000491137},\n",
       " 'ELP3': {'Pvalue': 0.000491965},\n",
       " 'PITPNM2': {'Pvalue': 0.000492973},\n",
       " 'SEPT3': {'Pvalue': 0.000499338},\n",
       " 'PNLIPRP1': {'Pvalue': 0.000500943},\n",
       " 'TMEM56': {'Pvalue': 0.000501294},\n",
       " 'PHF21B': {'Pvalue': 0.000502574},\n",
       " 'ASNS': {'Pvalue': 0.000504599},\n",
       " 'MKRN2': {'Pvalue': 0.000509433},\n",
       " 'KIAA0319': {'Pvalue': 0.000511197},\n",
       " 'UBASH3B': {'Pvalue': 0.000518204},\n",
       " 'DNAH1': {'Pvalue': 0.000520277},\n",
       " 'TMEM19': {'Pvalue': 0.000525203},\n",
       " 'KIAA1324L': {'Pvalue': 0.000526854},\n",
       " 'STAB1': {'Pvalue': 0.000526999},\n",
       " 'PHF3': {'Pvalue': 0.000527825},\n",
       " 'STRC': {'Pvalue': 0.000532089},\n",
       " 'TRIM9': {'Pvalue': 0.000533218},\n",
       " 'ISYNA1': {'Pvalue': 0.00053537},\n",
       " 'MAPK1': {'Pvalue': 0.000540888},\n",
       " 'HERC6': {'Pvalue': 0.000543554},\n",
       " 'GDE1': {'Pvalue': 0.000547542},\n",
       " 'MAP9': {'Pvalue': 0.000549917},\n",
       " 'CTNND2': {'Pvalue': 0.000553661},\n",
       " 'ATF1': {'Pvalue': 0.000557354},\n",
       " 'PLCL1': {'Pvalue': 0.000559131},\n",
       " 'ACE': {'Pvalue': 0.000559847},\n",
       " 'UNC13A': {'Pvalue': 0.00055988},\n",
       " 'GPR39': {'Pvalue': 0.000560285},\n",
       " 'TTC28': {'Pvalue': 0.000563859},\n",
       " 'SCRIB': {'Pvalue': 0.000566503},\n",
       " 'NDUFB9': {'Pvalue': 0.000567827},\n",
       " 'MTSS1': {'Pvalue': 0.000567827},\n",
       " 'CHRNB4': {'Pvalue': 0.000571815},\n",
       " 'PTPN5': {'Pvalue': 0.000572065},\n",
       " 'TBL1XR1': {'Pvalue': 0.0005724},\n",
       " 'LMAN2L': {'Pvalue': 0.000576445},\n",
       " 'SERINC4': {'Pvalue': 0.000580923},\n",
       " 'SERF2': {'Pvalue': 0.000580923},\n",
       " 'ZNF395': {'Pvalue': 0.000582095},\n",
       " 'FBXO16': {'Pvalue': 0.000582095},\n",
       " 'FMO2': {'Pvalue': 0.000583546},\n",
       " 'ACVR2B': {'Pvalue': 0.000583648},\n",
       " 'EXOG': {'Pvalue': 0.000583648},\n",
       " 'RNF165': {'Pvalue': 0.000585296},\n",
       " 'SMOC2': {'Pvalue': 0.000587712},\n",
       " 'GALNT12': {'Pvalue': 0.0005909},\n",
       " 'GNAO1': {'Pvalue': 0.000592432},\n",
       " 'AMFR': {'Pvalue': 0.000592432},\n",
       " 'GRM7': {'Pvalue': 0.000594638},\n",
       " 'WBP2NL': {'Pvalue': 0.000595601},\n",
       " 'SEMA3G': {'Pvalue': 0.000597894},\n",
       " 'LPP': {'Pvalue': 0.000601881},\n",
       " 'NOL4': {'Pvalue': 0.000602148},\n",
       " 'SMARCA5': {'Pvalue': 0.000604484},\n",
       " 'GIP': {'Pvalue': 0.000605005},\n",
       " 'MCC': {'Pvalue': 0.000605403},\n",
       " 'STRN': {'Pvalue': 0.000605441},\n",
       " 'SOSTDC1': {'Pvalue': 0.000606225},\n",
       " 'PSMA4': {'Pvalue': 0.000608037},\n",
       " 'DBH': {'Pvalue': 0.000619273},\n",
       " 'CCDC149': {'Pvalue': 0.000619991},\n",
       " 'UBAP2L': {'Pvalue': 0.000620587},\n",
       " 'HAX1': {'Pvalue': 0.000620587},\n",
       " 'IL17RB': {'Pvalue': 0.000625106},\n",
       " 'CLCN3': {'Pvalue': 0.000628422},\n",
       " 'L3MBTL4': {'Pvalue': 0.000631693},\n",
       " 'HIVEP2': {'Pvalue': 0.000633219},\n",
       " 'EP300': {'Pvalue': 0.000634004},\n",
       " 'ETV1': {'Pvalue': 0.000638447},\n",
       " 'NRBP2': {'Pvalue': 0.000638678},\n",
       " 'KCNJ13': {'Pvalue': 0.000639059},\n",
       " 'GABBR2': {'Pvalue': 0.000640963},\n",
       " 'STX1A': {'Pvalue': 0.000645375},\n",
       " 'MED30': {'Pvalue': 0.000648946},\n",
       " 'PAK6': {'Pvalue': 0.000652452},\n",
       " 'MCM9': {'Pvalue': 0.000652735},\n",
       " 'INA': {'Pvalue': 0.000653982},\n",
       " 'LRRK2': {'Pvalue': 0.000654729},\n",
       " 'ARSG': {'Pvalue': 0.000663201},\n",
       " 'PBX3': {'Pvalue': 0.000671735},\n",
       " 'COL4A2': {'Pvalue': 0.000675271},\n",
       " 'TMEM63C': {'Pvalue': 0.000675684},\n",
       " 'NGB': {'Pvalue': 0.000675684},\n",
       " 'MFAP1': {'Pvalue': 0.000676014},\n",
       " 'WDR76': {'Pvalue': 0.000676014},\n",
       " 'RP1L1': {'Pvalue': 0.000676888},\n",
       " 'AP3D1': {'Pvalue': 0.000682104},\n",
       " 'ZNF276': {'Pvalue': 0.000682564},\n",
       " 'HNRNPAB': {'Pvalue': 0.000683208},\n",
       " 'RBMXL2': {'Pvalue': 0.000685504},\n",
       " 'TCF12': {'Pvalue': 0.000686912},\n",
       " 'CD276': {'Pvalue': 0.000691242},\n",
       " 'MPHOSPH10': {'Pvalue': 0.0006933},\n",
       " 'XPNPEP3': {'Pvalue': 0.000694345},\n",
       " 'ZBBX': {'Pvalue': 0.000698958},\n",
       " 'CTNS': {'Pvalue': 0.000699924},\n",
       " 'NAGLU': {'Pvalue': 0.00070294},\n",
       " 'FAM114A2': {'Pvalue': 0.000704712},\n",
       " 'MFAP3': {'Pvalue': 0.000704712},\n",
       " 'PRKD1': {'Pvalue': 0.000705039},\n",
       " 'MCM3AP': {'Pvalue': 0.000708483},\n",
       " 'MRPL48': {'Pvalue': 0.000709216},\n",
       " 'DKK2': {'Pvalue': 0.000710255},\n",
       " 'SULT6B1': {'Pvalue': 0.000713992},\n",
       " 'FN3KRP': {'Pvalue': 0.000716775},\n",
       " 'NUP85': {'Pvalue': 0.000717165},\n",
       " 'ITPRIPL2': {'Pvalue': 0.000723052},\n",
       " 'SMARCAD1': {'Pvalue': 0.000723308},\n",
       " 'CEACAM16': {'Pvalue': 0.000731679},\n",
       " 'DUSP7': {'Pvalue': 0.000737323},\n",
       " 'LSM1': {'Pvalue': 0.00073788},\n",
       " 'BAG4': {'Pvalue': 0.00073788},\n",
       " 'GAL': {'Pvalue': 0.00074244},\n",
       " 'CNDP1': {'Pvalue': 0.000746392},\n",
       " 'NAGA': {'Pvalue': 0.000751401},\n",
       " 'DOK5': {'Pvalue': 0.000752946},\n",
       " 'GFM2': {'Pvalue': 0.000755317},\n",
       " 'TMEM182': {'Pvalue': 0.000759608},\n",
       " 'PSMD6': {'Pvalue': 0.000761887},\n",
       " 'MIDN': {'Pvalue': 0.000763802},\n",
       " 'NUCB2': {'Pvalue': 0.000764551},\n",
       " 'MPHOSPH9': {'Pvalue': 0.000767594},\n",
       " 'C12orf65': {'Pvalue': 0.000767594},\n",
       " 'CHD5': {'Pvalue': 0.000768739},\n",
       " 'MCHR1': {'Pvalue': 0.000774235},\n",
       " 'ZC3HC1': {'Pvalue': 0.000774882},\n",
       " 'DDX10': {'Pvalue': 0.00078235},\n",
       " 'SNAP91': {'Pvalue': 0.00078581},\n",
       " 'EPB41L3': {'Pvalue': 0.000788287},\n",
       " 'DGKD': {'Pvalue': 0.000791648},\n",
       " 'SMU1': {'Pvalue': 0.000792383},\n",
       " 'COL23A1': {'Pvalue': 0.000797211},\n",
       " 'SETD7': {'Pvalue': 0.000799535},\n",
       " 'AMPH': {'Pvalue': 0.000800262},\n",
       " 'CACNB2': {'Pvalue': 0.000807658},\n",
       " 'SMTNL2': {'Pvalue': 0.000812386},\n",
       " 'SORCS3': {'Pvalue': 0.000814273},\n",
       " 'GOSR1': {'Pvalue': 0.000815931},\n",
       " 'PRMT7': {'Pvalue': 0.000815962},\n",
       " 'SMPD3': {'Pvalue': 0.000815962},\n",
       " 'PNPT1': {'Pvalue': 0.000816004},\n",
       " 'EHBP1': {'Pvalue': 0.000818585},\n",
       " 'TMC5': {'Pvalue': 0.000824588},\n",
       " 'MAPK6': {'Pvalue': 0.000827829},\n",
       " 'PARP16': {'Pvalue': 0.00082831},\n",
       " 'DCDC2': {'Pvalue': 0.000833615},\n",
       " 'CDCA7L': {'Pvalue': 0.000834517},\n",
       " 'SEZ6L': {'Pvalue': 0.000845694},\n",
       " 'MBNL1': {'Pvalue': 0.00084594},\n",
       " 'PRKG1': {'Pvalue': 0.000849228},\n",
       " 'NDUFA12': {'Pvalue': 0.000849555},\n",
       " 'NOSTRIN': {'Pvalue': 0.000849896},\n",
       " 'LGR5': {'Pvalue': 0.000854875},\n",
       " 'ZNF592': {'Pvalue': 0.000856324},\n",
       " 'SRGAP1': {'Pvalue': 0.000856585},\n",
       " 'TMEM170B': {'Pvalue': 0.000859647},\n",
       " 'EIF5A2': {'Pvalue': 0.000859907},\n",
       " 'COL11A1': {'Pvalue': 0.000860692},\n",
       " 'PUF60': {'Pvalue': 0.000866029},\n",
       " 'PREX2': {'Pvalue': 0.000867583},\n",
       " 'MRPS7': {'Pvalue': 0.00087114},\n",
       " 'MIF4GD': {'Pvalue': 0.00087114},\n",
       " 'PSKH2': {'Pvalue': 0.00087223},\n",
       " 'FOXF1': {'Pvalue': 0.000875082},\n",
       " 'KLC1': {'Pvalue': 0.000875957},\n",
       " 'TP53BP1': {'Pvalue': 0.000877458},\n",
       " 'FREM1': {'Pvalue': 0.000878058},\n",
       " 'ZNF500': {'Pvalue': 0.000891269},\n",
       " 'SIPA1L1': {'Pvalue': 0.000891499},\n",
       " 'SNF8': {'Pvalue': 0.000891866},\n",
       " 'AMBRA1': {'Pvalue': 0.000895265},\n",
       " 'SCEL': {'Pvalue': 0.000901666},\n",
       " 'DNER': {'Pvalue': 0.000905735},\n",
       " 'SLC13A3': {'Pvalue': 0.000906082},\n",
       " 'FRMD4A': {'Pvalue': 0.000908245},\n",
       " 'SUMF2': {'Pvalue': 0.000910635},\n",
       " 'PHKG1': {'Pvalue': 0.000910635},\n",
       " 'FBXW4': {'Pvalue': 0.00091151},\n",
       " 'FAR2': {'Pvalue': 0.000915131},\n",
       " 'JAM3': {'Pvalue': 0.000919633},\n",
       " 'LHFPL3': {'Pvalue': 0.000920057},\n",
       " 'RPA1': {'Pvalue': 0.000920501},\n",
       " 'RBM18': {'Pvalue': 0.000925313},\n",
       " 'SHANK3': {'Pvalue': 0.000925318},\n",
       " 'ACR': {'Pvalue': 0.000925318},\n",
       " 'SIAE': {'Pvalue': 0.000928701},\n",
       " 'SPA17': {'Pvalue': 0.000928701},\n",
       " 'SSBP3': {'Pvalue': 0.000928708},\n",
       " 'BICD1': {'Pvalue': 0.000932811},\n",
       " 'TUBG1': {'Pvalue': 0.000935157},\n",
       " 'RABEP1': {'Pvalue': 0.000935344},\n",
       " 'GRIK1': {'Pvalue': 0.000937638},\n",
       " 'PELI2': {'Pvalue': 0.000940603},\n",
       " 'ELOVL6': {'Pvalue': 0.000942549},\n",
       " 'TXNRD1': {'Pvalue': 0.000944641},\n",
       " 'MGRN1': {'Pvalue': 0.000946651},\n",
       " 'DONSON': {'Pvalue': 0.000949987},\n",
       " 'GTF3A': {'Pvalue': 0.000950603},\n",
       " 'NRF1': {'Pvalue': 0.000952658},\n",
       " 'PCCB': {'Pvalue': 0.000959306},\n",
       " 'NUDT21': {'Pvalue': 0.000961743},\n",
       " 'LIFR': {'Pvalue': 0.000964076},\n",
       " 'MSL2': {'Pvalue': 0.000964308},\n",
       " 'FCF1': {'Pvalue': 0.000966796},\n",
       " 'PIM3': {'Pvalue': 0.000968821},\n",
       " 'STYK1': {'Pvalue': 0.000970238},\n",
       " 'HIST1H1D': {'Pvalue': 0.000970541},\n",
       " 'HIST1H4F': {'Pvalue': 0.000970541},\n",
       " 'HIST1H4G': {'Pvalue': 0.000970541},\n",
       " 'RBX1': {'Pvalue': 0.000973323},\n",
       " 'PDE4D': {'Pvalue': 0.00097563},\n",
       " 'MKL1': {'Pvalue': 0.000977875},\n",
       " 'CHD6': {'Pvalue': 0.000981347},\n",
       " 'CMTM4': {'Pvalue': 0.000982543},\n",
       " 'PTPRT': {'Pvalue': 0.000984075},\n",
       " 'PRDM15': {'Pvalue': 0.000985404},\n",
       " 'BANP': {'Pvalue': 0.000986327},\n",
       " 'MPP6': {'Pvalue': 0.000986539},\n",
       " 'EDEM1': {'Pvalue': 0.000989409},\n",
       " 'HSPD1': {'Pvalue': 0.000997449},\n",
       " 'HSPE1': {'Pvalue': 0.000997449},\n",
       " 'TUSC3': {'Pvalue': 0.00100471},\n",
       " 'IGF2BP3': {'Pvalue': 0.00100543},\n",
       " 'STK24': {'Pvalue': 0.0010112},\n",
       " 'ADAM12': {'Pvalue': 0.00101133},\n",
       " 'LSS': {'Pvalue': 0.00101227},\n",
       " 'FCER1A': {'Pvalue': 0.00101876},\n",
       " 'XRCC3': {'Pvalue': 0.00101922},\n",
       " 'NOP56': {'Pvalue': 0.00102482},\n",
       " 'IDH3B': {'Pvalue': 0.00102482},\n",
       " 'PTPDC1': {'Pvalue': 0.00102706},\n",
       " 'MPPED2': {'Pvalue': 0.00102745},\n",
       " 'GNG4': {'Pvalue': 0.0010297},\n",
       " 'SF3B1': {'Pvalue': 0.00103283},\n",
       " 'HEXB': {'Pvalue': 0.00103354},\n",
       " 'SLC1A1': {'Pvalue': 0.00103471},\n",
       " 'DDAH1': {'Pvalue': 0.00103796},\n",
       " 'ABHD2': {'Pvalue': 0.00104028},\n",
       " 'F11R': {'Pvalue': 0.00104218},\n",
       " 'USF1': {'Pvalue': 0.00104218},\n",
       " 'ARHGAP30': {'Pvalue': 0.00104218},\n",
       " 'ST3GAL1': {'Pvalue': 0.00104815},\n",
       " 'SSBP4': {'Pvalue': 0.00105192},\n",
       " 'OTUB2': {'Pvalue': 0.00105228},\n",
       " 'SIRPD': {'Pvalue': 0.00105319},\n",
       " 'LPAR2': {'Pvalue': 0.00105788},\n",
       " 'GMIP': {'Pvalue': 0.00105788},\n",
       " 'WNK2': {'Pvalue': 0.00105794},\n",
       " 'SLC26A3': {'Pvalue': 0.00105841},\n",
       " 'C9orf72': {'Pvalue': 0.00106612},\n",
       " 'EMCN': {'Pvalue': 0.00106649},\n",
       " 'GABRB1': {'Pvalue': 0.00106874},\n",
       " 'STRA8': {'Pvalue': 0.00106931},\n",
       " 'TEP1': {'Pvalue': 0.00107066},\n",
       " 'PTPRR': {'Pvalue': 0.00107111},\n",
       " 'UPK1B': {'Pvalue': 0.00107255},\n",
       " 'CYP4B1': {'Pvalue': 0.00108507},\n",
       " 'COQ10B': {'Pvalue': 0.00108901},\n",
       " 'DENND1A': {'Pvalue': 0.00109251},\n",
       " 'C16orf71': {'Pvalue': 0.00109979},\n",
       " 'NUBPL': {'Pvalue': 0.00110001},\n",
       " 'EDN2': {'Pvalue': 0.00110106},\n",
       " 'OGFOD1': {'Pvalue': 0.00110487},\n",
       " 'ZNF804B': {'Pvalue': 0.00110679},\n",
       " 'RBBP5': {'Pvalue': 0.00110703},\n",
       " 'FANCA': {'Pvalue': 0.0011124},\n",
       " 'CRYZ': {'Pvalue': 0.00112042},\n",
       " 'EFHD1': {'Pvalue': 0.00112395},\n",
       " 'DEFB134': {'Pvalue': 0.00112483},\n",
       " 'FAM49B': {'Pvalue': 0.00112561},\n",
       " 'SLC37A1': {'Pvalue': 0.00112776},\n",
       " 'ARC': {'Pvalue': 0.00112992},\n",
       " 'ELMOD1': {'Pvalue': 0.00112995},\n",
       " 'TNNC2': {'Pvalue': 0.0011301},\n",
       " 'SNX21': {'Pvalue': 0.0011301},\n",
       " 'DDC': {'Pvalue': 0.00113474},\n",
       " 'ZNF563': {'Pvalue': 0.00113706},\n",
       " 'DNAJA1': {'Pvalue': 0.0011384},\n",
       " 'IL1RL1': {'Pvalue': 0.00114676},\n",
       " 'ARRB1': {'Pvalue': 0.00115321},\n",
       " 'CHCHD3': {'Pvalue': 0.0011578},\n",
       " 'TKT': {'Pvalue': 0.00115899},\n",
       " 'POLL': {'Pvalue': 0.00116645},\n",
       " 'CDK2AP1': {'Pvalue': 0.00116774},\n",
       " 'ZNF214': {'Pvalue': 0.00116973},\n",
       " 'C16orf90': {'Pvalue': 0.00117286},\n",
       " 'CLUAP1': {'Pvalue': 0.00117286},\n",
       " 'EBNA1BP2': {'Pvalue': 0.0011755},\n",
       " 'PKN1': {'Pvalue': 0.00117797},\n",
       " 'PTGER1': {'Pvalue': 0.00117797},\n",
       " 'GIPC1': {'Pvalue': 0.00117797},\n",
       " 'SMC5': {'Pvalue': 0.00117859},\n",
       " 'SLC45A1': {'Pvalue': 0.00118018},\n",
       " 'SNX29': {'Pvalue': 0.00118096},\n",
       " 'ANKRD44': {'Pvalue': 0.00119255},\n",
       " 'KLHDC7A': {'Pvalue': 0.00119649},\n",
       " 'BHLHE22': {'Pvalue': 0.00119807},\n",
       " 'OR6Y1': {'Pvalue': 0.00119931},\n",
       " 'SLC33A1': {'Pvalue': 0.0012013},\n",
       " 'DDX50': {'Pvalue': 0.00120508},\n",
       " 'BEST3': {'Pvalue': 0.00120568},\n",
       " 'ESRRG': {'Pvalue': 0.00120746},\n",
       " 'SYT13': {'Pvalue': 0.00120859},\n",
       " 'PITPNC1': {'Pvalue': 0.00121433},\n",
       " 'SYT7': {'Pvalue': 0.00122545},\n",
       " 'MLX': {'Pvalue': 0.00122589},\n",
       " 'PSMC3IP': {'Pvalue': 0.00122589},\n",
       " 'BARX2': {'Pvalue': 0.00122723},\n",
       " 'ACOT8': {'Pvalue': 0.00123621},\n",
       " 'BTRC': {'Pvalue': 0.00123763},\n",
       " 'GEM': {'Pvalue': 0.0012411},\n",
       " 'SLC8A3': {'Pvalue': 0.00124222},\n",
       " 'IQCB1': {'Pvalue': 0.00124576},\n",
       " 'PRDM16': {'Pvalue': 0.00125675},\n",
       " 'UBE2Z': {'Pvalue': 0.00125778},\n",
       " 'DOK6': {'Pvalue': 0.00126678},\n",
       " 'DDHD2': {'Pvalue': 0.00126848},\n",
       " 'RORA': {'Pvalue': 0.00127115},\n",
       " 'NOS1': {'Pvalue': 0.00127217},\n",
       " 'ZNF778': {'Pvalue': 0.00127419},\n",
       " 'MAP3K9': {'Pvalue': 0.00127965},\n",
       " 'PROKR2': {'Pvalue': 0.00128064},\n",
       " 'KLHDC10': {'Pvalue': 0.00128075},\n",
       " 'CDK5RAP3': {'Pvalue': 0.00128115},\n",
       " 'TMEM135': {'Pvalue': 0.00128907},\n",
       " 'ACYP2': {'Pvalue': 0.00129089},\n",
       " 'POMT2': {'Pvalue': 0.00129342},\n",
       " 'MAML2': {'Pvalue': 0.00129601},\n",
       " 'SMAP2': {'Pvalue': 0.00129696},\n",
       " 'COLEC11': {'Pvalue': 0.00130636},\n",
       " 'VPS13C': {'Pvalue': 0.00131004},\n",
       " 'NR3C2': {'Pvalue': 0.00131015},\n",
       " 'SLC19A2': {'Pvalue': 0.00131094},\n",
       " 'VAV1': {'Pvalue': 0.00131479},\n",
       " 'RALBP1': {'Pvalue': 0.00131553},\n",
       " 'ELMO1': {'Pvalue': 0.00131762},\n",
       " 'CNTN6': {'Pvalue': 0.00132206},\n",
       " 'SOX11': {'Pvalue': 0.00133057},\n",
       " 'PLXDC1': {'Pvalue': 0.00133258},\n",
       " 'TRA2B': {'Pvalue': 0.00133421},\n",
       " 'TRPM3': {'Pvalue': 0.0013424},\n",
       " 'SGCG': {'Pvalue': 0.00134328},\n",
       " 'EBPL': {'Pvalue': 0.00134412},\n",
       " 'PTPRD': {'Pvalue': 0.00134546},\n",
       " 'SCML4': {'Pvalue': 0.00134745},\n",
       " 'EEF1A2': {'Pvalue': 0.00134763},\n",
       " 'RPS17': {'Pvalue': 0.00134774},\n",
       " 'PTPRZ1': {'Pvalue': 0.0013491},\n",
       " 'MTIF3': {'Pvalue': 0.00134978},\n",
       " 'GPC5': {'Pvalue': 0.00135051},\n",
       " 'NUP88': {'Pvalue': 0.00135181},\n",
       " 'ELAVL4': {'Pvalue': 0.00135459},\n",
       " 'MEGF6': {'Pvalue': 0.00135565},\n",
       " 'CNIH3': {'Pvalue': 0.00135841},\n",
       " 'FAM20A': {'Pvalue': 0.00135965},\n",
       " 'DGKB': {'Pvalue': 0.00136338},\n",
       " 'ZCCHC7': {'Pvalue': 0.00136785},\n",
       " 'UBTD2': {'Pvalue': 0.00137214},\n",
       " 'GREM1': {'Pvalue': 0.00137975},\n",
       " 'CCBE1': {'Pvalue': 0.00138011},\n",
       " 'CRLF3': {'Pvalue': 0.00138051},\n",
       " 'GDPD5': {'Pvalue': 0.0013824},\n",
       " 'DTNBP1': {'Pvalue': 0.00138256},\n",
       " 'GSTZ1': {'Pvalue': 0.00138458},\n",
       " 'ASB5': {'Pvalue': 0.00139073},\n",
       " 'RFTN2': {'Pvalue': 0.00139248},\n",
       " 'BEST1': {'Pvalue': 0.00139852},\n",
       " 'PHF2': {'Pvalue': 0.00140286},\n",
       " 'ANKS1B': {'Pvalue': 0.00140304},\n",
       " 'SDR9C7': {'Pvalue': 0.00140419},\n",
       " 'ST18': {'Pvalue': 0.0014061},\n",
       " 'DGKZ': {'Pvalue': 0.00140708},\n",
       " 'MDK': {'Pvalue': 0.00140708},\n",
       " 'HDAC9': {'Pvalue': 0.00141263},\n",
       " 'NKAIN3': {'Pvalue': 0.00142043},\n",
       " 'FRMD5': {'Pvalue': 0.00142361},\n",
       " 'EIF2AK4': {'Pvalue': 0.00142411},\n",
       " 'IFNK': {'Pvalue': 0.00143694},\n",
       " 'ITGBL1': {'Pvalue': 0.00144167},\n",
       " 'KIF18A': {'Pvalue': 0.00144222},\n",
       " 'ZNF407': {'Pvalue': 0.00144526},\n",
       " 'NMT2': {'Pvalue': 0.00145065},\n",
       " 'SFN': {'Pvalue': 0.00145231},\n",
       " 'NKX6-3': {'Pvalue': 0.00145358},\n",
       " 'ANK1': {'Pvalue': 0.00145358},\n",
       " 'COL21A1': {'Pvalue': 0.00145993},\n",
       " 'SLC6A1': {'Pvalue': 0.00146058},\n",
       " 'ZMAT4': {'Pvalue': 0.00146249},\n",
       " 'VTI1A': {'Pvalue': 0.0014639},\n",
       " 'TUBGCP4': {'Pvalue': 0.00146424},\n",
       " 'NTNG2': {'Pvalue': 0.00146518},\n",
       " 'NEK1': {'Pvalue': 0.0014671},\n",
       " 'ACYP1': {'Pvalue': 0.00147452},\n",
       " 'KIAA1958': {'Pvalue': 0.00148287},\n",
       " 'ADAL': {'Pvalue': 0.00148908},\n",
       " 'ZNF670': {'Pvalue': 0.0015082},\n",
       " 'RANGAP1': {'Pvalue': 0.00151151},\n",
       " 'CDH2': {'Pvalue': 0.00151543},\n",
       " 'ECT2': {'Pvalue': 0.00151567},\n",
       " 'FOXA2': {'Pvalue': 0.00151584},\n",
       " 'RPL36AL': {'Pvalue': 0.00151625},\n",
       " 'MGAT2': {'Pvalue': 0.00151625},\n",
       " 'OAZ1': {'Pvalue': 0.00151718},\n",
       " 'LINGO3': {'Pvalue': 0.00151718},\n",
       " 'CLEC18B': {'Pvalue': 0.00151943},\n",
       " 'UBXN7': {'Pvalue': 0.00152297},\n",
       " 'PPP2R2B': {'Pvalue': 0.00152453},\n",
       " 'ZDHHC20': {'Pvalue': 0.00152522},\n",
       " 'KLRC1': {'Pvalue': 0.00152531},\n",
       " 'ARHGAP18': {'Pvalue': 0.00152701},\n",
       " 'PARVB': {'Pvalue': 0.00153164},\n",
       " 'IQCE': {'Pvalue': 0.00154052},\n",
       " 'SLC5A7': {'Pvalue': 0.00154376},\n",
       " 'CYP2C18': {'Pvalue': 0.00154447},\n",
       " 'CA10': {'Pvalue': 0.00154531},\n",
       " 'HINT1': {'Pvalue': 0.00155254},\n",
       " 'LYRM7': {'Pvalue': 0.00155254},\n",
       " 'GRIN3A': {'Pvalue': 0.00155551},\n",
       " 'SLC12A5': {'Pvalue': 0.00155673},\n",
       " 'NPEPL1': {'Pvalue': 0.00156203},\n",
       " 'ZSCAN29': {'Pvalue': 0.00156325},\n",
       " 'TSHR': {'Pvalue': 0.00156723},\n",
       " 'KALRN': {'Pvalue': 0.00157132},\n",
       " 'MATR3': {'Pvalue': 0.00157161},\n",
       " 'PAIP2': {'Pvalue': 0.00157161},\n",
       " 'SACS': {'Pvalue': 0.00157207},\n",
       " 'C17orf98': {'Pvalue': 0.00157503},\n",
       " 'KLRK1': {'Pvalue': 0.00157682},\n",
       " 'PDE3A': {'Pvalue': 0.001578},\n",
       " 'RNF2': {'Pvalue': 0.00157947},\n",
       " 'SNAP23': {'Pvalue': 0.00157947},\n",
       " 'KCTD21': {'Pvalue': 0.00158157},\n",
       " 'SIPA1L2': {'Pvalue': 0.00158319},\n",
       " 'CPA1': {'Pvalue': 0.0015846},\n",
       " 'ITGB4': {'Pvalue': 0.00158578},\n",
       " 'GALK1': {'Pvalue': 0.00158578},\n",
       " 'GPRC5D': {'Pvalue': 0.0015869},\n",
       " 'FAM183A': {'Pvalue': 0.00159193},\n",
       " 'PARN': {'Pvalue': 0.00159865},\n",
       " 'SLCO3A1': {'Pvalue': 0.00159914},\n",
       " 'ANKRD26': {'Pvalue': 0.00160109},\n",
       " 'IL17A': {'Pvalue': 0.00160358},\n",
       " 'GRK5': {'Pvalue': 0.00160789},\n",
       " 'ELOVL3': {'Pvalue': 0.00160802},\n",
       " 'PITX3': {'Pvalue': 0.00160802},\n",
       " 'GALNTL6': {'Pvalue': 0.00161729},\n",
       " 'NPR2': {'Pvalue': 0.00163168},\n",
       " 'SPAG8': {'Pvalue': 0.00163168},\n",
       " 'HINT2': {'Pvalue': 0.00163168},\n",
       " 'FOXK1': {'Pvalue': 0.00163449},\n",
       " 'SRP54': {'Pvalue': 0.00163731},\n",
       " 'GPN1': {'Pvalue': 0.00163829},\n",
       " 'HARBI1': {'Pvalue': 0.00163859},\n",
       " 'GNRHR': {'Pvalue': 0.0016398},\n",
       " 'EXOC2': {'Pvalue': 0.00164019},\n",
       " 'HUS1B': {'Pvalue': 0.00164019},\n",
       " 'TASP1': {'Pvalue': 0.00164206},\n",
       " 'CHST11': {'Pvalue': 0.00164294},\n",
       " 'RPS6KA1': {'Pvalue': 0.00165255},\n",
       " 'SYT16': {'Pvalue': 0.00165358},\n",
       " 'PCSK6': {'Pvalue': 0.00166691},\n",
       " 'FOXN3': {'Pvalue': 0.00166928},\n",
       " 'ASTN1': {'Pvalue': 0.00167091},\n",
       " 'ZNF385D': {'Pvalue': 0.00167332},\n",
       " 'ABCC8': {'Pvalue': 0.00167383},\n",
       " 'DPP6': {'Pvalue': 0.00167392},\n",
       " 'ABCF2': {'Pvalue': 0.00167441},\n",
       " 'BPI': {'Pvalue': 0.00167949},\n",
       " 'ARMC1': {'Pvalue': 0.00168075},\n",
       " 'TRDN': {'Pvalue': 0.0016893},\n",
       " 'RGS10': {'Pvalue': 0.00168999},\n",
       " 'TNIP1': {'Pvalue': 0.00169033},\n",
       " 'MLKL': {'Pvalue': 0.00169081},\n",
       " 'PRKCQ': {'Pvalue': 0.0016939},\n",
       " 'C6': {'Pvalue': 0.00169678},\n",
       " 'RANBP3L': {'Pvalue': 0.00169796},\n",
       " 'RPL37A': {'Pvalue': 0.00170586},\n",
       " 'LRRC2': {'Pvalue': 0.00171494},\n",
       " 'TDGF1': {'Pvalue': 0.00171494},\n",
       " 'CKLF': {'Pvalue': 0.00171523},\n",
       " 'CMTM1': {'Pvalue': 0.00171523},\n",
       " 'CMTM2': {'Pvalue': 0.00171523},\n",
       " 'CD58': {'Pvalue': 0.0017182},\n",
       " 'NDRG2': {'Pvalue': 0.00172804},\n",
       " 'TPPP2': {'Pvalue': 0.00172804},\n",
       " 'RNASE13': {'Pvalue': 0.00172804},\n",
       " 'RNASE7': {'Pvalue': 0.00172804},\n",
       " 'LRRC57': {'Pvalue': 0.00172867},\n",
       " 'CAB39L': {'Pvalue': 0.00173455},\n",
       " 'CTNNA2': {'Pvalue': 0.0017379},\n",
       " 'TM4SF19': {'Pvalue': 0.00173897},\n",
       " 'NLGN1': {'Pvalue': 0.00174197},\n",
       " 'AGBL5': {'Pvalue': 0.00174318},\n",
       " 'LCMT2': {'Pvalue': 0.00174364},\n",
       " 'GRM1': {'Pvalue': 0.00174664},\n",
       " 'SLC9A3': {'Pvalue': 0.00175834},\n",
       " 'SUPT7L': {'Pvalue': 0.00176317},\n",
       " 'ZFYVE28': {'Pvalue': 0.00176894},\n",
       " 'GLB1L2': {'Pvalue': 0.0017697},\n",
       " 'B3GAT1': {'Pvalue': 0.0017697},\n",
       " 'C11orf24': {'Pvalue': 0.00177361},\n",
       " 'FBXL17': {'Pvalue': 0.00177381},\n",
       " 'ATXN7': {'Pvalue': 0.00177882},\n",
       " 'FBXO31': {'Pvalue': 0.0017825},\n",
       " 'DUSP13': {'Pvalue': 0.00178463},\n",
       " 'SAMD8': {'Pvalue': 0.00178463},\n",
       " 'NCOR2': {'Pvalue': 0.00178495},\n",
       " 'LAPTM5': {'Pvalue': 0.00179808},\n",
       " 'MFN2': {'Pvalue': 0.00179848},\n",
       " 'CABP2': {'Pvalue': 0.00180021},\n",
       " 'TPP2': {'Pvalue': 0.00180491},\n",
       " 'SULT1C4': {'Pvalue': 0.00180526},\n",
       " 'SLC2A2': {'Pvalue': 0.00180712},\n",
       " 'IREB2': {'Pvalue': 0.00181764},\n",
       " 'SMG6': {'Pvalue': 0.00181928},\n",
       " 'ZNF622': {'Pvalue': 0.0018226},\n",
       " 'NAT2': {'Pvalue': 0.00182661},\n",
       " 'SMOC1': {'Pvalue': 0.00183169},\n",
       " 'SLCO1C1': {'Pvalue': 0.00183636},\n",
       " 'MAMDC2': {'Pvalue': 0.00183862},\n",
       " 'SVOP': {'Pvalue': 0.00184011},\n",
       " 'SPTY2D1': {'Pvalue': 0.00184251},\n",
       " 'USP10': {'Pvalue': 0.00184341},\n",
       " 'H3F3B': {'Pvalue': 0.00184445},\n",
       " 'UNK': {'Pvalue': 0.00184445},\n",
       " 'FGFR1': {'Pvalue': 0.00184596},\n",
       " 'SMAD3': {'Pvalue': 0.00184939},\n",
       " 'PTGIS': {'Pvalue': 0.00185222},\n",
       " 'NLRP14': {'Pvalue': 0.00185336},\n",
       " 'PIPOX': {'Pvalue': 0.00186041},\n",
       " 'CTGF': {'Pvalue': 0.00186306},\n",
       " 'GNA13': {'Pvalue': 0.00187275},\n",
       " 'CDK3': {'Pvalue': 0.00187402},\n",
       " 'EVPL': {'Pvalue': 0.00187402},\n",
       " 'RPGRIP1L': {'Pvalue': 0.00187623},\n",
       " 'EAF2': {'Pvalue': 0.00188521},\n",
       " ...}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genes_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifications\n",
    "gene_class = [1 if g in genes_p and genes_p[g][\"Pvalue\"] <= 0.00000005 else 0 for g in pcnet.nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "pclap = nx.laplacian_matrix(pcnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding information to the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.set_node_attributes(pcnet, values = genes_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Community detection\n",
    "\n",
    "Detect communities within PCNet and perform predictions on those communities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine classification\n",
    "\n",
    "We can try stratifying genes based on a binary feature vector of gene-gene associations from PCNet with the predicted value as GWAS significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package sklearn.svm in sklearn:\n",
      "\n",
      "NAME\n",
      "    sklearn.svm - The :mod:`sklearn.svm` module includes Support Vector Machine algorithms.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    base\n",
      "    bounds\n",
      "    classes\n",
      "    liblinear\n",
      "    libsvm\n",
      "    libsvm_sparse\n",
      "    setup\n",
      "    tests (package)\n",
      "\n",
      "CLASSES\n",
      "    sklearn.base.BaseEstimator(builtins.object)\n",
      "        sklearn.svm.classes.LinearSVC(sklearn.base.BaseEstimator, sklearn.linear_model.base.LinearClassifierMixin, sklearn.linear_model.base.SparseCoefMixin)\n",
      "    sklearn.base.RegressorMixin(builtins.object)\n",
      "        sklearn.svm.classes.LinearSVR(sklearn.linear_model.base.LinearModel, sklearn.base.RegressorMixin)\n",
      "        sklearn.svm.classes.NuSVR(sklearn.svm.base.BaseLibSVM, sklearn.base.RegressorMixin)\n",
      "        sklearn.svm.classes.SVR(sklearn.svm.base.BaseLibSVM, sklearn.base.RegressorMixin)\n",
      "    sklearn.linear_model.base.LinearClassifierMixin(sklearn.base.ClassifierMixin)\n",
      "        sklearn.svm.classes.LinearSVC(sklearn.base.BaseEstimator, sklearn.linear_model.base.LinearClassifierMixin, sklearn.linear_model.base.SparseCoefMixin)\n",
      "    sklearn.linear_model.base.LinearModel(abc.NewBase)\n",
      "        sklearn.svm.classes.LinearSVR(sklearn.linear_model.base.LinearModel, sklearn.base.RegressorMixin)\n",
      "    sklearn.linear_model.base.SparseCoefMixin(builtins.object)\n",
      "        sklearn.svm.classes.LinearSVC(sklearn.base.BaseEstimator, sklearn.linear_model.base.LinearClassifierMixin, sklearn.linear_model.base.SparseCoefMixin)\n",
      "    sklearn.svm.base.BaseLibSVM(abc.NewBase)\n",
      "        sklearn.svm.classes.NuSVR(sklearn.svm.base.BaseLibSVM, sklearn.base.RegressorMixin)\n",
      "        sklearn.svm.classes.OneClassSVM\n",
      "        sklearn.svm.classes.SVR(sklearn.svm.base.BaseLibSVM, sklearn.base.RegressorMixin)\n",
      "    sklearn.svm.base.BaseSVC(abc.NewBase)\n",
      "        sklearn.svm.classes.NuSVC\n",
      "        sklearn.svm.classes.SVC\n",
      "    \n",
      "    class LinearSVC(sklearn.base.BaseEstimator, sklearn.linear_model.base.LinearClassifierMixin, sklearn.linear_model.base.SparseCoefMixin)\n",
      "     |  Linear Support Vector Classification.\n",
      "     |  \n",
      "     |  Similar to SVC with parameter kernel='linear', but implemented in terms of\n",
      "     |  liblinear rather than libsvm, so it has more flexibility in the choice of\n",
      "     |  penalties and loss functions and should scale better to large numbers of\n",
      "     |  samples.\n",
      "     |  \n",
      "     |  This class supports both dense and sparse input and the multiclass support\n",
      "     |  is handled according to a one-vs-the-rest scheme.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <svm_classification>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  penalty : string, 'l1' or 'l2' (default='l2')\n",
      "     |      Specifies the norm used in the penalization. The 'l2'\n",
      "     |      penalty is the standard used in SVC. The 'l1' leads to ``coef_``\n",
      "     |      vectors that are sparse.\n",
      "     |  \n",
      "     |  loss : string, 'hinge' or 'squared_hinge' (default='squared_hinge')\n",
      "     |      Specifies the loss function. 'hinge' is the standard SVM loss\n",
      "     |      (used e.g. by the SVC class) while 'squared_hinge' is the\n",
      "     |      square of the hinge loss.\n",
      "     |  \n",
      "     |  dual : bool, (default=True)\n",
      "     |      Select the algorithm to either solve the dual or primal\n",
      "     |      optimization problem. Prefer dual=False when n_samples > n_features.\n",
      "     |  \n",
      "     |  tol : float, optional (default=1e-4)\n",
      "     |      Tolerance for stopping criteria.\n",
      "     |  \n",
      "     |  C : float, optional (default=1.0)\n",
      "     |      Penalty parameter C of the error term.\n",
      "     |  \n",
      "     |  multi_class : string, 'ovr' or 'crammer_singer' (default='ovr')\n",
      "     |      Determines the multi-class strategy if `y` contains more than\n",
      "     |      two classes.\n",
      "     |      ``\"ovr\"`` trains n_classes one-vs-rest classifiers, while\n",
      "     |      ``\"crammer_singer\"`` optimizes a joint objective over all classes.\n",
      "     |      While `crammer_singer` is interesting from a theoretical perspective\n",
      "     |      as it is consistent, it is seldom used in practice as it rarely leads\n",
      "     |      to better accuracy and is more expensive to compute.\n",
      "     |      If ``\"crammer_singer\"`` is chosen, the options loss, penalty and dual\n",
      "     |      will be ignored.\n",
      "     |  \n",
      "     |  fit_intercept : boolean, optional (default=True)\n",
      "     |      Whether to calculate the intercept for this model. If set\n",
      "     |      to false, no intercept will be used in calculations\n",
      "     |      (i.e. data is expected to be already centered).\n",
      "     |  \n",
      "     |  intercept_scaling : float, optional (default=1)\n",
      "     |      When self.fit_intercept is True, instance vector x becomes\n",
      "     |      ``[x, self.intercept_scaling]``,\n",
      "     |      i.e. a \"synthetic\" feature with constant value equals to\n",
      "     |      intercept_scaling is appended to the instance vector.\n",
      "     |      The intercept becomes intercept_scaling * synthetic feature weight\n",
      "     |      Note! the synthetic feature weight is subject to l1/l2 regularization\n",
      "     |      as all other features.\n",
      "     |      To lessen the effect of regularization on synthetic feature weight\n",
      "     |      (and therefore on the intercept) intercept_scaling has to be increased.\n",
      "     |  \n",
      "     |  class_weight : {dict, 'balanced'}, optional\n",
      "     |      Set the parameter C of class i to ``class_weight[i]*C`` for\n",
      "     |      SVC. If not given, all classes are supposed to have\n",
      "     |      weight one.\n",
      "     |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      "     |      weights inversely proportional to class frequencies in the input data\n",
      "     |      as ``n_samples / (n_classes * np.bincount(y))``\n",
      "     |  \n",
      "     |  verbose : int, (default=0)\n",
      "     |      Enable verbose output. Note that this setting takes advantage of a\n",
      "     |      per-process runtime setting in liblinear that, if enabled, may not work\n",
      "     |      properly in a multithreaded context.\n",
      "     |  \n",
      "     |  random_state : int, RandomState instance or None, optional (default=None)\n",
      "     |      The seed of the pseudo random number generator to use when shuffling\n",
      "     |      the data.  If int, random_state is the seed used by the random number\n",
      "     |      generator; If RandomState instance, random_state is the random number\n",
      "     |      generator; If None, the random number generator is the RandomState\n",
      "     |      instance used by `np.random`.\n",
      "     |  \n",
      "     |  max_iter : int, (default=1000)\n",
      "     |      The maximum number of iterations to be run.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  coef_ : array, shape = [n_features] if n_classes == 2 else [n_classes, n_features]\n",
      "     |      Weights assigned to the features (coefficients in the primal\n",
      "     |      problem). This is only available in the case of a linear kernel.\n",
      "     |  \n",
      "     |      ``coef_`` is a readonly property derived from ``raw_coef_`` that\n",
      "     |      follows the internal memory layout of liblinear.\n",
      "     |  \n",
      "     |  intercept_ : array, shape = [1] if n_classes == 2 else [n_classes]\n",
      "     |      Constants in decision function.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.svm import LinearSVC\n",
      "     |  >>> from sklearn.datasets import make_classification\n",
      "     |  >>> X, y = make_classification(n_features=4, random_state=0)\n",
      "     |  >>> clf = LinearSVC(random_state=0)\n",
      "     |  >>> clf.fit(X, y)\n",
      "     |  LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     |       intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     |       multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
      "     |       verbose=0)\n",
      "     |  >>> print(clf.coef_)\n",
      "     |  [[ 0.08551385  0.39414796  0.49847831  0.37513797]]\n",
      "     |  >>> print(clf.intercept_)\n",
      "     |  [ 0.28418066]\n",
      "     |  >>> print(clf.predict([[0, 0, 0, 0]]))\n",
      "     |  [1]\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  The underlying C implementation uses a random number generator to\n",
      "     |  select features when fitting the model. It is thus not uncommon\n",
      "     |  to have slightly different results for the same input data. If\n",
      "     |  that happens, try with a smaller ``tol`` parameter.\n",
      "     |  \n",
      "     |  The underlying implementation, liblinear, uses a sparse internal\n",
      "     |  representation for the data that will incur a memory copy.\n",
      "     |  \n",
      "     |  Predict output may not match that of standalone liblinear in certain\n",
      "     |  cases. See :ref:`differences from liblinear <liblinear_differences>`\n",
      "     |  in the narrative documentation.\n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  `LIBLINEAR: A Library for Large Linear Classification\n",
      "     |  <http://www.csie.ntu.edu.tw/~cjlin/liblinear/>`__\n",
      "     |  \n",
      "     |  See also\n",
      "     |  --------\n",
      "     |  SVC\n",
      "     |      Implementation of Support Vector Machine classifier using libsvm:\n",
      "     |      the kernel can be non-linear but its SMO algorithm does not\n",
      "     |      scale to large number of samples as LinearSVC does.\n",
      "     |  \n",
      "     |      Furthermore SVC multi-class mode is implemented using one\n",
      "     |      vs one scheme while LinearSVC uses one vs the rest. It is\n",
      "     |      possible to implement one vs the rest with SVC by using the\n",
      "     |      :class:`sklearn.multiclass.OneVsRestClassifier` wrapper.\n",
      "     |  \n",
      "     |      Finally SVC can fit dense data without memory copy if the input\n",
      "     |      is C-contiguous. Sparse data will still incur memory copy though.\n",
      "     |  \n",
      "     |  sklearn.linear_model.SGDClassifier\n",
      "     |      SGDClassifier can optimize the same cost function as LinearSVC\n",
      "     |      by adjusting the penalty and loss parameters. In addition it requires\n",
      "     |      less memory, allows incremental (online) learning, and implements\n",
      "     |      various loss functions and regularization regimes.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LinearSVC\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.linear_model.base.LinearClassifierMixin\n",
      "     |      sklearn.base.ClassifierMixin\n",
      "     |      sklearn.linear_model.base.SparseCoefMixin\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, penalty='l2', loss='squared_hinge', dual=True, tol=0.0001, C=1.0, multi_class='ovr', fit_intercept=True, intercept_scaling=1, class_weight=None, verbose=0, random_state=None, max_iter=1000)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit(self, X, y, sample_weight=None)\n",
      "     |      Fit the model according to the given training data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      "     |          Training vector, where n_samples in the number of samples and\n",
      "     |          n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like, shape = [n_samples]\n",
      "     |          Target vector relative to X\n",
      "     |      \n",
      "     |      sample_weight : array-like, shape = [n_samples], optional\n",
      "     |          Array of weights that are assigned to individual\n",
      "     |          samples. If not provided,\n",
      "     |          then each sample is given unit weight.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : boolean, optional\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : mapping of string to any\n",
      "     |          Parameter names mapped to their values.\n",
      "     |  \n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |      \n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as pipelines). The latter have parameters of the form\n",
      "     |      ``<component>__<parameter>`` so that it's possible to update each\n",
      "     |      component of a nested object.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model.base.LinearClassifierMixin:\n",
      "     |  \n",
      "     |  decision_function(self, X)\n",
      "     |      Predict confidence scores for samples.\n",
      "     |      \n",
      "     |      The confidence score for a sample is the signed distance of that\n",
      "     |      sample to the hyperplane.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix}, shape = (n_samples, n_features)\n",
      "     |          Samples.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)\n",
      "     |          Confidence scores per (sample, class) combination. In the binary\n",
      "     |          case, confidence score for self.classes_[1] where >0 means this\n",
      "     |          class would be predicted.\n",
      "     |  \n",
      "     |  predict(self, X)\n",
      "     |      Predict class labels for samples in X.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      "     |          Samples.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : array, shape = [n_samples]\n",
      "     |          Predicted class label per sample.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      "     |  \n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Returns the mean accuracy on the given test data and labels.\n",
      "     |      \n",
      "     |      In multi-label classification, this is the subset accuracy\n",
      "     |      which is a harsh metric since you require for each sample that\n",
      "     |      each label set be correctly predicted.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like, shape = (n_samples, n_features)\n",
      "     |          Test samples.\n",
      "     |      \n",
      "     |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      "     |          True labels for X.\n",
      "     |      \n",
      "     |      sample_weight : array-like, shape = [n_samples], optional\n",
      "     |          Sample weights.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          Mean accuracy of self.predict(X) wrt. y.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model.base.SparseCoefMixin:\n",
      "     |  \n",
      "     |  densify(self)\n",
      "     |      Convert coefficient matrix to dense array format.\n",
      "     |      \n",
      "     |      Converts the ``coef_`` member (back) to a numpy.ndarray. This is the\n",
      "     |      default format of ``coef_`` and is required for fitting, so calling\n",
      "     |      this method is only required on models that have previously been\n",
      "     |      sparsified; otherwise, it is a no-op.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator\n",
      "     |  \n",
      "     |  sparsify(self)\n",
      "     |      Convert coefficient matrix to sparse format.\n",
      "     |      \n",
      "     |      Converts the ``coef_`` member to a scipy.sparse matrix, which for\n",
      "     |      L1-regularized models can be much more memory- and storage-efficient\n",
      "     |      than the usual numpy.ndarray representation.\n",
      "     |      \n",
      "     |      The ``intercept_`` member is not converted.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For non-sparse models, i.e. when there are not many zeros in ``coef_``,\n",
      "     |      this may actually *increase* memory usage, so use this method with\n",
      "     |      care. A rule of thumb is that the number of zero elements, which can\n",
      "     |      be computed with ``(coef_ == 0).sum()``, must be more than 50% for this\n",
      "     |      to provide significant benefits.\n",
      "     |      \n",
      "     |      After calling this method, further fitting with the partial_fit\n",
      "     |      method (if any) will not work until you call densify.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator\n",
      "    \n",
      "    class LinearSVR(sklearn.linear_model.base.LinearModel, sklearn.base.RegressorMixin)\n",
      "     |  Linear Support Vector Regression.\n",
      "     |  \n",
      "     |  Similar to SVR with parameter kernel='linear', but implemented in terms of\n",
      "     |  liblinear rather than libsvm, so it has more flexibility in the choice of\n",
      "     |  penalties and loss functions and should scale better to large numbers of\n",
      "     |  samples.\n",
      "     |  \n",
      "     |  This class supports both dense and sparse input.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <svm_regression>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  C : float, optional (default=1.0)\n",
      "     |      Penalty parameter C of the error term. The penalty is a squared\n",
      "     |      l2 penalty. The bigger this parameter, the less regularization is used.\n",
      "     |  \n",
      "     |  loss : string, 'epsilon_insensitive' or 'squared_epsilon_insensitive' (default='epsilon_insensitive')\n",
      "     |      Specifies the loss function. 'l1' is the epsilon-insensitive loss\n",
      "     |      (standard SVR) while 'l2' is the squared epsilon-insensitive loss.\n",
      "     |  \n",
      "     |  epsilon : float, optional (default=0.1)\n",
      "     |      Epsilon parameter in the epsilon-insensitive loss function. Note\n",
      "     |      that the value of this parameter depends on the scale of the target\n",
      "     |      variable y. If unsure, set ``epsilon=0``.\n",
      "     |  \n",
      "     |  dual : bool, (default=True)\n",
      "     |      Select the algorithm to either solve the dual or primal\n",
      "     |      optimization problem. Prefer dual=False when n_samples > n_features.\n",
      "     |  \n",
      "     |  tol : float, optional (default=1e-4)\n",
      "     |      Tolerance for stopping criteria.\n",
      "     |  \n",
      "     |  fit_intercept : boolean, optional (default=True)\n",
      "     |      Whether to calculate the intercept for this model. If set\n",
      "     |      to false, no intercept will be used in calculations\n",
      "     |      (i.e. data is expected to be already centered).\n",
      "     |  \n",
      "     |  intercept_scaling : float, optional (default=1)\n",
      "     |      When self.fit_intercept is True, instance vector x becomes\n",
      "     |      [x, self.intercept_scaling],\n",
      "     |      i.e. a \"synthetic\" feature with constant value equals to\n",
      "     |      intercept_scaling is appended to the instance vector.\n",
      "     |      The intercept becomes intercept_scaling * synthetic feature weight\n",
      "     |      Note! the synthetic feature weight is subject to l1/l2 regularization\n",
      "     |      as all other features.\n",
      "     |      To lessen the effect of regularization on synthetic feature weight\n",
      "     |      (and therefore on the intercept) intercept_scaling has to be increased.\n",
      "     |  \n",
      "     |  verbose : int, (default=0)\n",
      "     |      Enable verbose output. Note that this setting takes advantage of a\n",
      "     |      per-process runtime setting in liblinear that, if enabled, may not work\n",
      "     |      properly in a multithreaded context.\n",
      "     |  \n",
      "     |  random_state : int, RandomState instance or None, optional (default=None)\n",
      "     |      The seed of the pseudo random number generator to use when shuffling\n",
      "     |      the data.  If int, random_state is the seed used by the random number\n",
      "     |      generator; If RandomState instance, random_state is the random number\n",
      "     |      generator; If None, the random number generator is the RandomState\n",
      "     |      instance used by `np.random`.\n",
      "     |  \n",
      "     |  max_iter : int, (default=1000)\n",
      "     |      The maximum number of iterations to be run.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  coef_ : array, shape = [n_features] if n_classes == 2 else [n_classes, n_features]\n",
      "     |      Weights assigned to the features (coefficients in the primal\n",
      "     |      problem). This is only available in the case of a linear kernel.\n",
      "     |  \n",
      "     |      `coef_` is a readonly property derived from `raw_coef_` that\n",
      "     |      follows the internal memory layout of liblinear.\n",
      "     |  \n",
      "     |  intercept_ : array, shape = [1] if n_classes == 2 else [n_classes]\n",
      "     |      Constants in decision function.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.svm import LinearSVR\n",
      "     |  >>> from sklearn.datasets import make_regression\n",
      "     |  >>> X, y = make_regression(n_features=4, random_state=0)\n",
      "     |  >>> regr = LinearSVR(random_state=0)\n",
      "     |  >>> regr.fit(X, y)\n",
      "     |  LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True,\n",
      "     |       intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
      "     |       random_state=0, tol=0.0001, verbose=0)\n",
      "     |  >>> print(regr.coef_)\n",
      "     |  [ 16.35750999  26.91499923  42.30652207  60.47843124]\n",
      "     |  >>> print(regr.intercept_)\n",
      "     |  [-4.29756543]\n",
      "     |  >>> print(regr.predict([[0, 0, 0, 0]]))\n",
      "     |  [-4.29756543]\n",
      "     |  \n",
      "     |  See also\n",
      "     |  --------\n",
      "     |  LinearSVC\n",
      "     |      Implementation of Support Vector Machine classifier using the\n",
      "     |      same library as this class (liblinear).\n",
      "     |  \n",
      "     |  SVR\n",
      "     |      Implementation of Support Vector Machine regression using libsvm:\n",
      "     |      the kernel can be non-linear but its SMO algorithm does not\n",
      "     |      scale to large number of samples as LinearSVC does.\n",
      "     |  \n",
      "     |  sklearn.linear_model.SGDRegressor\n",
      "     |      SGDRegressor can optimize the same cost function as LinearSVR\n",
      "     |      by adjusting the penalty and loss parameters. In addition it requires\n",
      "     |      less memory, allows incremental (online) learning, and implements\n",
      "     |      various loss functions and regularization regimes.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LinearSVR\n",
      "     |      sklearn.linear_model.base.LinearModel\n",
      "     |      abc.NewBase\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.base.RegressorMixin\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, epsilon=0.0, tol=0.0001, C=1.0, loss='epsilon_insensitive', fit_intercept=True, intercept_scaling=1.0, dual=True, verbose=0, random_state=None, max_iter=1000)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit(self, X, y, sample_weight=None)\n",
      "     |      Fit the model according to the given training data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      "     |          Training vector, where n_samples in the number of samples and\n",
      "     |          n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like, shape = [n_samples]\n",
      "     |          Target vector relative to X\n",
      "     |      \n",
      "     |      sample_weight : array-like, shape = [n_samples], optional\n",
      "     |          Array of weights that are assigned to individual\n",
      "     |          samples. If not provided,\n",
      "     |          then each sample is given unit weight.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model.base.LinearModel:\n",
      "     |  \n",
      "     |  predict(self, X)\n",
      "     |      Predict using the linear model\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix}, shape = (n_samples, n_features)\n",
      "     |          Samples.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : array, shape = (n_samples,)\n",
      "     |          Returns predicted values.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : boolean, optional\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : mapping of string to any\n",
      "     |          Parameter names mapped to their values.\n",
      "     |  \n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |      \n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as pipelines). The latter have parameters of the form\n",
      "     |      ``<component>__<parameter>`` so that it's possible to update each\n",
      "     |      component of a nested object.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.RegressorMixin:\n",
      "     |  \n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Returns the coefficient of determination R^2 of the prediction.\n",
      "     |      \n",
      "     |      The coefficient R^2 is defined as (1 - u/v), where u is the residual\n",
      "     |      sum of squares ((y_true - y_pred) ** 2).sum() and v is the total\n",
      "     |      sum of squares ((y_true - y_true.mean()) ** 2).sum().\n",
      "     |      The best possible score is 1.0 and it can be negative (because the\n",
      "     |      model can be arbitrarily worse). A constant model that always\n",
      "     |      predicts the expected value of y, disregarding the input features,\n",
      "     |      would get a R^2 score of 0.0.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like, shape = (n_samples, n_features)\n",
      "     |          Test samples.\n",
      "     |      \n",
      "     |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      "     |          True values for X.\n",
      "     |      \n",
      "     |      sample_weight : array-like, shape = [n_samples], optional\n",
      "     |          Sample weights.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          R^2 of self.predict(X) wrt. y.\n",
      "    \n",
      "    class NuSVC(sklearn.svm.base.BaseSVC)\n",
      "     |  Nu-Support Vector Classification.\n",
      "     |  \n",
      "     |  Similar to SVC but uses a parameter to control the number of support\n",
      "     |  vectors.\n",
      "     |  \n",
      "     |  The implementation is based on libsvm.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <svm_classification>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  nu : float, optional (default=0.5)\n",
      "     |      An upper bound on the fraction of training errors and a lower\n",
      "     |      bound of the fraction of support vectors. Should be in the\n",
      "     |      interval (0, 1].\n",
      "     |  \n",
      "     |  kernel : string, optional (default='rbf')\n",
      "     |       Specifies the kernel type to be used in the algorithm.\n",
      "     |       It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
      "     |       a callable.\n",
      "     |       If none is given, 'rbf' will be used. If a callable is given it is\n",
      "     |       used to precompute the kernel matrix.\n",
      "     |  \n",
      "     |  degree : int, optional (default=3)\n",
      "     |      Degree of the polynomial kernel function ('poly').\n",
      "     |      Ignored by all other kernels.\n",
      "     |  \n",
      "     |  gamma : float, optional (default='auto')\n",
      "     |      Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
      "     |      If gamma is 'auto' then 1/n_features will be used instead.\n",
      "     |  \n",
      "     |  coef0 : float, optional (default=0.0)\n",
      "     |      Independent term in kernel function.\n",
      "     |      It is only significant in 'poly' and 'sigmoid'.\n",
      "     |  \n",
      "     |  probability : boolean, optional (default=False)\n",
      "     |      Whether to enable probability estimates. This must be enabled prior\n",
      "     |      to calling `fit`, and will slow down that method.\n",
      "     |  \n",
      "     |  shrinking : boolean, optional (default=True)\n",
      "     |      Whether to use the shrinking heuristic.\n",
      "     |  \n",
      "     |  tol : float, optional (default=1e-3)\n",
      "     |      Tolerance for stopping criterion.\n",
      "     |  \n",
      "     |  cache_size : float, optional\n",
      "     |      Specify the size of the kernel cache (in MB).\n",
      "     |  \n",
      "     |  class_weight : {dict, 'balanced'}, optional\n",
      "     |      Set the parameter C of class i to class_weight[i]*C for\n",
      "     |      SVC. If not given, all classes are supposed to have\n",
      "     |      weight one. The \"balanced\" mode uses the values of y to automatically\n",
      "     |      adjust weights inversely proportional to class frequencies as\n",
      "     |      ``n_samples / (n_classes * np.bincount(y))``\n",
      "     |  \n",
      "     |  verbose : bool, default: False\n",
      "     |      Enable verbose output. Note that this setting takes advantage of a\n",
      "     |      per-process runtime setting in libsvm that, if enabled, may not work\n",
      "     |      properly in a multithreaded context.\n",
      "     |  \n",
      "     |  max_iter : int, optional (default=-1)\n",
      "     |      Hard limit on iterations within solver, or -1 for no limit.\n",
      "     |  \n",
      "     |  decision_function_shape : 'ovo', 'ovr', default='ovr'\n",
      "     |      Whether to return a one-vs-rest ('ovr') decision function of shape\n",
      "     |      (n_samples, n_classes) as all other classifiers, or the original\n",
      "     |      one-vs-one ('ovo') decision function of libsvm which has shape\n",
      "     |      (n_samples, n_classes * (n_classes - 1) / 2).\n",
      "     |  \n",
      "     |      .. versionchanged:: 0.19\n",
      "     |          decision_function_shape is 'ovr' by default.\n",
      "     |  \n",
      "     |      .. versionadded:: 0.17\n",
      "     |         *decision_function_shape='ovr'* is recommended.\n",
      "     |  \n",
      "     |      .. versionchanged:: 0.17\n",
      "     |         Deprecated *decision_function_shape='ovo' and None*.\n",
      "     |  \n",
      "     |  random_state : int, RandomState instance or None, optional (default=None)\n",
      "     |      The seed of the pseudo random number generator to use when shuffling\n",
      "     |      the data.  If int, random_state is the seed used by the random number\n",
      "     |      generator; If RandomState instance, random_state is the random number\n",
      "     |      generator; If None, the random number generator is the RandomState\n",
      "     |      instance used by `np.random`.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  support_ : array-like, shape = [n_SV]\n",
      "     |      Indices of support vectors.\n",
      "     |  \n",
      "     |  support_vectors_ : array-like, shape = [n_SV, n_features]\n",
      "     |      Support vectors.\n",
      "     |  \n",
      "     |  n_support_ : array-like, dtype=int32, shape = [n_class]\n",
      "     |      Number of support vectors for each class.\n",
      "     |  \n",
      "     |  dual_coef_ : array, shape = [n_class-1, n_SV]\n",
      "     |      Coefficients of the support vector in the decision function.\n",
      "     |      For multiclass, coefficient for all 1-vs-1 classifiers.\n",
      "     |      The layout of the coefficients in the multiclass case is somewhat\n",
      "     |      non-trivial. See the section about multi-class classification in\n",
      "     |      the SVM section of the User Guide for details.\n",
      "     |  \n",
      "     |  coef_ : array, shape = [n_class-1, n_features]\n",
      "     |      Weights assigned to the features (coefficients in the primal\n",
      "     |      problem). This is only available in the case of a linear kernel.\n",
      "     |  \n",
      "     |      `coef_` is readonly property derived from `dual_coef_` and\n",
      "     |      `support_vectors_`.\n",
      "     |  \n",
      "     |  intercept_ : array, shape = [n_class * (n_class-1) / 2]\n",
      "     |      Constants in decision function.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
      "     |  >>> y = np.array([1, 1, 2, 2])\n",
      "     |  >>> from sklearn.svm import NuSVC\n",
      "     |  >>> clf = NuSVC()\n",
      "     |  >>> clf.fit(X, y) #doctest: +NORMALIZE_WHITESPACE\n",
      "     |  NuSVC(cache_size=200, class_weight=None, coef0=0.0,\n",
      "     |        decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "     |        max_iter=-1, nu=0.5, probability=False, random_state=None,\n",
      "     |        shrinking=True, tol=0.001, verbose=False)\n",
      "     |  >>> print(clf.predict([[-0.8, -1]]))\n",
      "     |  [1]\n",
      "     |  \n",
      "     |  See also\n",
      "     |  --------\n",
      "     |  SVC\n",
      "     |      Support Vector Machine for classification using libsvm.\n",
      "     |  \n",
      "     |  LinearSVC\n",
      "     |      Scalable linear Support Vector Machine for classification using\n",
      "     |      liblinear.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      NuSVC\n",
      "     |      sklearn.svm.base.BaseSVC\n",
      "     |      abc.NewBase\n",
      "     |      sklearn.svm.base.BaseLibSVM\n",
      "     |      abc.NewBase\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.base.ClassifierMixin\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, nu=0.5, kernel='rbf', degree=3, gamma='auto', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', random_state=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.svm.base.BaseSVC:\n",
      "     |  \n",
      "     |  decision_function(self, X)\n",
      "     |      Distance of the samples X to the separating hyperplane.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like, shape (n_samples, n_features)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X : array-like, shape (n_samples, n_classes * (n_classes-1) / 2)\n",
      "     |          Returns the decision function of the sample for each class\n",
      "     |          in the model.\n",
      "     |          If decision_function_shape='ovr', the shape is (n_samples,\n",
      "     |          n_classes)\n",
      "     |  \n",
      "     |  predict(self, X)\n",
      "     |      Perform classification on samples in X.\n",
      "     |      \n",
      "     |      For an one-class model, +1 or -1 is returned.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      "     |          For kernel=\"precomputed\", the expected shape of X is\n",
      "     |          [n_samples_test, n_samples_train]\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y_pred : array, shape (n_samples,)\n",
      "     |          Class labels for samples in X.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.svm.base.BaseSVC:\n",
      "     |  \n",
      "     |  predict_log_proba\n",
      "     |      Compute log probabilities of possible outcomes for samples in X.\n",
      "     |      \n",
      "     |      The model need to have probability information computed at training\n",
      "     |      time: fit with attribute `probability` set to True.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like, shape (n_samples, n_features)\n",
      "     |          For kernel=\"precomputed\", the expected shape of X is\n",
      "     |          [n_samples_test, n_samples_train]\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      T : array-like, shape (n_samples, n_classes)\n",
      "     |          Returns the log-probabilities of the sample for each class in\n",
      "     |          the model. The columns correspond to the classes in sorted\n",
      "     |          order, as they appear in the attribute `classes_`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability model is created using cross validation, so\n",
      "     |      the results can be slightly different than those obtained by\n",
      "     |      predict. Also, it will produce meaningless results on very small\n",
      "     |      datasets.\n",
      "     |  \n",
      "     |  predict_proba\n",
      "     |      Compute probabilities of possible outcomes for samples in X.\n",
      "     |      \n",
      "     |      The model need to have probability information computed at training\n",
      "     |      time: fit with attribute `probability` set to True.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like, shape (n_samples, n_features)\n",
      "     |          For kernel=\"precomputed\", the expected shape of X is\n",
      "     |          [n_samples_test, n_samples_train]\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      T : array-like, shape (n_samples, n_classes)\n",
      "     |          Returns the probability of the sample for each class in\n",
      "     |          the model. The columns correspond to the classes in sorted\n",
      "     |          order, as they appear in the attribute `classes_`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability model is created using cross validation, so\n",
      "     |      the results can be slightly different than those obtained by\n",
      "     |      predict. Also, it will produce meaningless results on very small\n",
      "     |      datasets.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.svm.base.BaseLibSVM:\n",
      "     |  \n",
      "     |  fit(self, X, y, sample_weight=None)\n",
      "     |      Fit the SVM model according to the given training data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      "     |          Training vectors, where n_samples is the number of samples\n",
      "     |          and n_features is the number of features.\n",
      "     |          For kernel=\"precomputed\", the expected shape of X is\n",
      "     |          (n_samples, n_samples).\n",
      "     |      \n",
      "     |      y : array-like, shape (n_samples,)\n",
      "     |          Target values (class labels in classification, real numbers in\n",
      "     |          regression)\n",
      "     |      \n",
      "     |      sample_weight : array-like, shape (n_samples,)\n",
      "     |          Per-sample weights. Rescale C per sample. Higher weights\n",
      "     |          force the classifier to put more emphasis on these points.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns self.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      ------\n",
      "     |      If X and y are not C-ordered and contiguous arrays of np.float64 and\n",
      "     |      X is not a scipy.sparse.csr_matrix, X and/or y may be copied.\n",
      "     |      \n",
      "     |      If X is a dense array, then the other methods will not support sparse\n",
      "     |      matrices as input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.svm.base.BaseLibSVM:\n",
      "     |  \n",
      "     |  coef_\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : boolean, optional\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : mapping of string to any\n",
      "     |          Parameter names mapped to their values.\n",
      "     |  \n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |      \n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as pipelines). The latter have parameters of the form\n",
      "     |      ``<component>__<parameter>`` so that it's possible to update each\n",
      "     |      component of a nested object.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      "     |  \n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Returns the mean accuracy on the given test data and labels.\n",
      "     |      \n",
      "     |      In multi-label classification, this is the subset accuracy\n",
      "     |      which is a harsh metric since you require for each sample that\n",
      "     |      each label set be correctly predicted.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like, shape = (n_samples, n_features)\n",
      "     |          Test samples.\n",
      "     |      \n",
      "     |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      "     |          True labels for X.\n",
      "     |      \n",
      "     |      sample_weight : array-like, shape = [n_samples], optional\n",
      "     |          Sample weights.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          Mean accuracy of self.predict(X) wrt. y.\n",
      "    \n",
      "    class NuSVR(sklearn.svm.base.BaseLibSVM, sklearn.base.RegressorMixin)\n",
      "     |  Nu Support Vector Regression.\n",
      "     |  \n",
      "     |  Similar to NuSVC, for regression, uses a parameter nu to control\n",
      "     |  the number of support vectors. However, unlike NuSVC, where nu\n",
      "     |  replaces C, here nu replaces the parameter epsilon of epsilon-SVR.\n",
      "     |  \n",
      "     |  The implementation is based on libsvm.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <svm_regression>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  C : float, optional (default=1.0)\n",
      "     |      Penalty parameter C of the error term.\n",
      "     |  \n",
      "     |  nu : float, optional\n",
      "     |      An upper bound on the fraction of training errors and a lower bound of\n",
      "     |      the fraction of support vectors. Should be in the interval (0, 1].  By\n",
      "     |      default 0.5 will be taken.\n",
      "     |  \n",
      "     |  kernel : string, optional (default='rbf')\n",
      "     |       Specifies the kernel type to be used in the algorithm.\n",
      "     |       It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
      "     |       a callable.\n",
      "     |       If none is given, 'rbf' will be used. If a callable is given it is\n",
      "     |       used to precompute the kernel matrix.\n",
      "     |  \n",
      "     |  degree : int, optional (default=3)\n",
      "     |      Degree of the polynomial kernel function ('poly').\n",
      "     |      Ignored by all other kernels.\n",
      "     |  \n",
      "     |  gamma : float, optional (default='auto')\n",
      "     |      Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
      "     |      If gamma is 'auto' then 1/n_features will be used instead.\n",
      "     |  \n",
      "     |  coef0 : float, optional (default=0.0)\n",
      "     |      Independent term in kernel function.\n",
      "     |      It is only significant in 'poly' and 'sigmoid'.\n",
      "     |  \n",
      "     |  shrinking : boolean, optional (default=True)\n",
      "     |      Whether to use the shrinking heuristic.\n",
      "     |  \n",
      "     |  tol : float, optional (default=1e-3)\n",
      "     |      Tolerance for stopping criterion.\n",
      "     |  \n",
      "     |  cache_size : float, optional\n",
      "     |      Specify the size of the kernel cache (in MB).\n",
      "     |  \n",
      "     |  verbose : bool, default: False\n",
      "     |      Enable verbose output. Note that this setting takes advantage of a\n",
      "     |      per-process runtime setting in libsvm that, if enabled, may not work\n",
      "     |      properly in a multithreaded context.\n",
      "     |  \n",
      "     |  max_iter : int, optional (default=-1)\n",
      "     |      Hard limit on iterations within solver, or -1 for no limit.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  support_ : array-like, shape = [n_SV]\n",
      "     |      Indices of support vectors.\n",
      "     |  \n",
      "     |  support_vectors_ : array-like, shape = [nSV, n_features]\n",
      "     |      Support vectors.\n",
      "     |  \n",
      "     |  dual_coef_ : array, shape = [1, n_SV]\n",
      "     |      Coefficients of the support vector in the decision function.\n",
      "     |  \n",
      "     |  coef_ : array, shape = [1, n_features]\n",
      "     |      Weights assigned to the features (coefficients in the primal\n",
      "     |      problem). This is only available in the case of a linear kernel.\n",
      "     |  \n",
      "     |      `coef_` is readonly property derived from `dual_coef_` and\n",
      "     |      `support_vectors_`.\n",
      "     |  \n",
      "     |  intercept_ : array, shape = [1]\n",
      "     |      Constants in decision function.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.svm import NuSVR\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> n_samples, n_features = 10, 5\n",
      "     |  >>> np.random.seed(0)\n",
      "     |  >>> y = np.random.randn(n_samples)\n",
      "     |  >>> X = np.random.randn(n_samples, n_features)\n",
      "     |  >>> clf = NuSVR(C=1.0, nu=0.1)\n",
      "     |  >>> clf.fit(X, y)  #doctest: +NORMALIZE_WHITESPACE\n",
      "     |  NuSVR(C=1.0, cache_size=200, coef0=0.0, degree=3, gamma='auto',\n",
      "     |        kernel='rbf', max_iter=-1, nu=0.1, shrinking=True, tol=0.001,\n",
      "     |        verbose=False)\n",
      "     |  \n",
      "     |  See also\n",
      "     |  --------\n",
      "     |  NuSVC\n",
      "     |      Support Vector Machine for classification implemented with libsvm\n",
      "     |      with a parameter to control the number of support vectors.\n",
      "     |  \n",
      "     |  SVR\n",
      "     |      epsilon Support Vector Machine for regression implemented with libsvm.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      NuSVR\n",
      "     |      sklearn.svm.base.BaseLibSVM\n",
      "     |      abc.NewBase\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.base.RegressorMixin\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, nu=0.5, C=1.0, kernel='rbf', degree=3, gamma='auto', coef0=0.0, shrinking=True, tol=0.001, cache_size=200, verbose=False, max_iter=-1)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.svm.base.BaseLibSVM:\n",
      "     |  \n",
      "     |  fit(self, X, y, sample_weight=None)\n",
      "     |      Fit the SVM model according to the given training data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      "     |          Training vectors, where n_samples is the number of samples\n",
      "     |          and n_features is the number of features.\n",
      "     |          For kernel=\"precomputed\", the expected shape of X is\n",
      "     |          (n_samples, n_samples).\n",
      "     |      \n",
      "     |      y : array-like, shape (n_samples,)\n",
      "     |          Target values (class labels in classification, real numbers in\n",
      "     |          regression)\n",
      "     |      \n",
      "     |      sample_weight : array-like, shape (n_samples,)\n",
      "     |          Per-sample weights. Rescale C per sample. Higher weights\n",
      "     |          force the classifier to put more emphasis on these points.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns self.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      ------\n",
      "     |      If X and y are not C-ordered and contiguous arrays of np.float64 and\n",
      "     |      X is not a scipy.sparse.csr_matrix, X and/or y may be copied.\n",
      "     |      \n",
      "     |      If X is a dense array, then the other methods will not support sparse\n",
      "     |      matrices as input.\n",
      "     |  \n",
      "     |  predict(self, X)\n",
      "     |      Perform regression on samples in X.\n",
      "     |      \n",
      "     |      For an one-class model, +1 (inlier) or -1 (outlier) is returned.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      "     |          For kernel=\"precomputed\", the expected shape of X is\n",
      "     |          (n_samples_test, n_samples_train).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y_pred : array, shape (n_samples,)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.svm.base.BaseLibSVM:\n",
      "     |  \n",
      "     |  coef_\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : boolean, optional\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : mapping of string to any\n",
      "     |          Parameter names mapped to their values.\n",
      "     |  \n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |      \n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as pipelines). The latter have parameters of the form\n",
      "     |      ``<component>__<parameter>`` so that it's possible to update each\n",
      "     |      component of a nested object.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.RegressorMixin:\n",
      "     |  \n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Returns the coefficient of determination R^2 of the prediction.\n",
      "     |      \n",
      "     |      The coefficient R^2 is defined as (1 - u/v), where u is the residual\n",
      "     |      sum of squares ((y_true - y_pred) ** 2).sum() and v is the total\n",
      "     |      sum of squares ((y_true - y_true.mean()) ** 2).sum().\n",
      "     |      The best possible score is 1.0 and it can be negative (because the\n",
      "     |      model can be arbitrarily worse). A constant model that always\n",
      "     |      predicts the expected value of y, disregarding the input features,\n",
      "     |      would get a R^2 score of 0.0.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like, shape = (n_samples, n_features)\n",
      "     |          Test samples.\n",
      "     |      \n",
      "     |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      "     |          True values for X.\n",
      "     |      \n",
      "     |      sample_weight : array-like, shape = [n_samples], optional\n",
      "     |          Sample weights.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          R^2 of self.predict(X) wrt. y.\n",
      "    \n",
      "    class OneClassSVM(sklearn.svm.base.BaseLibSVM)\n",
      "     |  Unsupervised Outlier Detection.\n",
      "     |  \n",
      "     |  Estimate the support of a high-dimensional distribution.\n",
      "     |  \n",
      "     |  The implementation is based on libsvm.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <svm_outlier_detection>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  kernel : string, optional (default='rbf')\n",
      "     |       Specifies the kernel type to be used in the algorithm.\n",
      "     |       It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
      "     |       a callable.\n",
      "     |       If none is given, 'rbf' will be used. If a callable is given it is\n",
      "     |       used to precompute the kernel matrix.\n",
      "     |  \n",
      "     |  nu : float, optional\n",
      "     |      An upper bound on the fraction of training\n",
      "     |      errors and a lower bound of the fraction of support\n",
      "     |      vectors. Should be in the interval (0, 1]. By default 0.5\n",
      "     |      will be taken.\n",
      "     |  \n",
      "     |  degree : int, optional (default=3)\n",
      "     |      Degree of the polynomial kernel function ('poly').\n",
      "     |      Ignored by all other kernels.\n",
      "     |  \n",
      "     |  gamma : float, optional (default='auto')\n",
      "     |      Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
      "     |      If gamma is 'auto' then 1/n_features will be used instead.\n",
      "     |  \n",
      "     |  coef0 : float, optional (default=0.0)\n",
      "     |      Independent term in kernel function.\n",
      "     |      It is only significant in 'poly' and 'sigmoid'.\n",
      "     |  \n",
      "     |  tol : float, optional\n",
      "     |      Tolerance for stopping criterion.\n",
      "     |  \n",
      "     |  shrinking : boolean, optional\n",
      "     |      Whether to use the shrinking heuristic.\n",
      "     |  \n",
      "     |  cache_size : float, optional\n",
      "     |      Specify the size of the kernel cache (in MB).\n",
      "     |  \n",
      "     |  verbose : bool, default: False\n",
      "     |      Enable verbose output. Note that this setting takes advantage of a\n",
      "     |      per-process runtime setting in libsvm that, if enabled, may not work\n",
      "     |      properly in a multithreaded context.\n",
      "     |  \n",
      "     |  max_iter : int, optional (default=-1)\n",
      "     |      Hard limit on iterations within solver, or -1 for no limit.\n",
      "     |  \n",
      "     |  random_state : int, RandomState instance or None, optional (default=None)\n",
      "     |      The seed of the pseudo random number generator to use when shuffling\n",
      "     |      the data.  If int, random_state is the seed used by the random number\n",
      "     |      generator; If RandomState instance, random_state is the random number\n",
      "     |      generator; If None, the random number generator is the RandomState\n",
      "     |      instance used by `np.random`.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  support_ : array-like, shape = [n_SV]\n",
      "     |      Indices of support vectors.\n",
      "     |  \n",
      "     |  support_vectors_ : array-like, shape = [nSV, n_features]\n",
      "     |      Support vectors.\n",
      "     |  \n",
      "     |  dual_coef_ : array, shape = [1, n_SV]\n",
      "     |      Coefficients of the support vectors in the decision function.\n",
      "     |  \n",
      "     |  coef_ : array, shape = [1, n_features]\n",
      "     |      Weights assigned to the features (coefficients in the primal\n",
      "     |      problem). This is only available in the case of a linear kernel.\n",
      "     |  \n",
      "     |      `coef_` is readonly property derived from `dual_coef_` and\n",
      "     |      `support_vectors_`\n",
      "     |  \n",
      "     |  intercept_ : array, shape = [1,]\n",
      "     |      Constant in the decision function.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      OneClassSVM\n",
      "     |      sklearn.svm.base.BaseLibSVM\n",
      "     |      abc.NewBase\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, kernel='rbf', degree=3, gamma='auto', coef0=0.0, tol=0.001, nu=0.5, shrinking=True, cache_size=200, verbose=False, max_iter=-1, random_state=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  decision_function(self, X)\n",
      "     |      Signed distance to the separating hyperplane.\n",
      "     |      \n",
      "     |      Signed distance is positive for an inlier and negative for an outlier.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like, shape (n_samples, n_features)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X : array-like, shape (n_samples,)\n",
      "     |          Returns the decision function of the samples.\n",
      "     |  \n",
      "     |  fit(self, X, y=None, sample_weight=None, **params)\n",
      "     |      Detects the soft boundary of the set of samples X.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      "     |          Set of samples, where n_samples is the number of samples and\n",
      "     |          n_features is the number of features.\n",
      "     |      \n",
      "     |      sample_weight : array-like, shape (n_samples,)\n",
      "     |          Per-sample weights. Rescale C per sample. Higher weights\n",
      "     |          force the classifier to put more emphasis on these points.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns self.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If X is not a C-ordered contiguous array it is copied.\n",
      "     |  \n",
      "     |  predict(self, X)\n",
      "     |      Perform classification on samples in X.\n",
      "     |      \n",
      "     |      For an one-class model, +1 or -1 is returned.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      "     |          For kernel=\"precomputed\", the expected shape of X is\n",
      "     |          [n_samples_test, n_samples_train]\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y_pred : array, shape (n_samples,)\n",
      "     |          Class labels for samples in X.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.svm.base.BaseLibSVM:\n",
      "     |  \n",
      "     |  coef_\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : boolean, optional\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : mapping of string to any\n",
      "     |          Parameter names mapped to their values.\n",
      "     |  \n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |      \n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as pipelines). The latter have parameters of the form\n",
      "     |      ``<component>__<parameter>`` so that it's possible to update each\n",
      "     |      component of a nested object.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class SVC(sklearn.svm.base.BaseSVC)\n",
      "     |  C-Support Vector Classification.\n",
      "     |  \n",
      "     |  The implementation is based on libsvm. The fit time complexity\n",
      "     |  is more than quadratic with the number of samples which makes it hard\n",
      "     |  to scale to dataset with more than a couple of 10000 samples.\n",
      "     |  \n",
      "     |  The multiclass support is handled according to a one-vs-one scheme.\n",
      "     |  \n",
      "     |  For details on the precise mathematical formulation of the provided\n",
      "     |  kernel functions and how `gamma`, `coef0` and `degree` affect each\n",
      "     |  other, see the corresponding section in the narrative documentation:\n",
      "     |  :ref:`svm_kernels`.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <svm_classification>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  C : float, optional (default=1.0)\n",
      "     |      Penalty parameter C of the error term.\n",
      "     |  \n",
      "     |  kernel : string, optional (default='rbf')\n",
      "     |       Specifies the kernel type to be used in the algorithm.\n",
      "     |       It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
      "     |       a callable.\n",
      "     |       If none is given, 'rbf' will be used. If a callable is given it is\n",
      "     |       used to pre-compute the kernel matrix from data matrices; that matrix\n",
      "     |       should be an array of shape ``(n_samples, n_samples)``.\n",
      "     |  \n",
      "     |  degree : int, optional (default=3)\n",
      "     |      Degree of the polynomial kernel function ('poly').\n",
      "     |      Ignored by all other kernels.\n",
      "     |  \n",
      "     |  gamma : float, optional (default='auto')\n",
      "     |      Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
      "     |      If gamma is 'auto' then 1/n_features will be used instead.\n",
      "     |  \n",
      "     |  coef0 : float, optional (default=0.0)\n",
      "     |      Independent term in kernel function.\n",
      "     |      It is only significant in 'poly' and 'sigmoid'.\n",
      "     |  \n",
      "     |  probability : boolean, optional (default=False)\n",
      "     |      Whether to enable probability estimates. This must be enabled prior\n",
      "     |      to calling `fit`, and will slow down that method.\n",
      "     |  \n",
      "     |  shrinking : boolean, optional (default=True)\n",
      "     |      Whether to use the shrinking heuristic.\n",
      "     |  \n",
      "     |  tol : float, optional (default=1e-3)\n",
      "     |      Tolerance for stopping criterion.\n",
      "     |  \n",
      "     |  cache_size : float, optional\n",
      "     |      Specify the size of the kernel cache (in MB).\n",
      "     |  \n",
      "     |  class_weight : {dict, 'balanced'}, optional\n",
      "     |      Set the parameter C of class i to class_weight[i]*C for\n",
      "     |      SVC. If not given, all classes are supposed to have\n",
      "     |      weight one.\n",
      "     |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      "     |      weights inversely proportional to class frequencies in the input data\n",
      "     |      as ``n_samples / (n_classes * np.bincount(y))``\n",
      "     |  \n",
      "     |  verbose : bool, default: False\n",
      "     |      Enable verbose output. Note that this setting takes advantage of a\n",
      "     |      per-process runtime setting in libsvm that, if enabled, may not work\n",
      "     |      properly in a multithreaded context.\n",
      "     |  \n",
      "     |  max_iter : int, optional (default=-1)\n",
      "     |      Hard limit on iterations within solver, or -1 for no limit.\n",
      "     |  \n",
      "     |  decision_function_shape : 'ovo', 'ovr', default='ovr'\n",
      "     |      Whether to return a one-vs-rest ('ovr') decision function of shape\n",
      "     |      (n_samples, n_classes) as all other classifiers, or the original\n",
      "     |      one-vs-one ('ovo') decision function of libsvm which has shape\n",
      "     |      (n_samples, n_classes * (n_classes - 1) / 2).\n",
      "     |  \n",
      "     |      .. versionchanged:: 0.19\n",
      "     |          decision_function_shape is 'ovr' by default.\n",
      "     |  \n",
      "     |      .. versionadded:: 0.17\n",
      "     |         *decision_function_shape='ovr'* is recommended.\n",
      "     |  \n",
      "     |      .. versionchanged:: 0.17\n",
      "     |         Deprecated *decision_function_shape='ovo' and None*.\n",
      "     |  \n",
      "     |  random_state : int, RandomState instance or None, optional (default=None)\n",
      "     |      The seed of the pseudo random number generator to use when shuffling\n",
      "     |      the data.  If int, random_state is the seed used by the random number\n",
      "     |      generator; If RandomState instance, random_state is the random number\n",
      "     |      generator; If None, the random number generator is the RandomState\n",
      "     |      instance used by `np.random`.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  support_ : array-like, shape = [n_SV]\n",
      "     |      Indices of support vectors.\n",
      "     |  \n",
      "     |  support_vectors_ : array-like, shape = [n_SV, n_features]\n",
      "     |      Support vectors.\n",
      "     |  \n",
      "     |  n_support_ : array-like, dtype=int32, shape = [n_class]\n",
      "     |      Number of support vectors for each class.\n",
      "     |  \n",
      "     |  dual_coef_ : array, shape = [n_class-1, n_SV]\n",
      "     |      Coefficients of the support vector in the decision function.\n",
      "     |      For multiclass, coefficient for all 1-vs-1 classifiers.\n",
      "     |      The layout of the coefficients in the multiclass case is somewhat\n",
      "     |      non-trivial. See the section about multi-class classification in the\n",
      "     |      SVM section of the User Guide for details.\n",
      "     |  \n",
      "     |  coef_ : array, shape = [n_class-1, n_features]\n",
      "     |      Weights assigned to the features (coefficients in the primal\n",
      "     |      problem). This is only available in the case of a linear kernel.\n",
      "     |  \n",
      "     |      `coef_` is a readonly property derived from `dual_coef_` and\n",
      "     |      `support_vectors_`.\n",
      "     |  \n",
      "     |  intercept_ : array, shape = [n_class * (n_class-1) / 2]\n",
      "     |      Constants in decision function.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
      "     |  >>> y = np.array([1, 1, 2, 2])\n",
      "     |  >>> from sklearn.svm import SVC\n",
      "     |  >>> clf = SVC()\n",
      "     |  >>> clf.fit(X, y) #doctest: +NORMALIZE_WHITESPACE\n",
      "     |  SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "     |      decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "     |      max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "     |      tol=0.001, verbose=False)\n",
      "     |  >>> print(clf.predict([[-0.8, -1]]))\n",
      "     |  [1]\n",
      "     |  \n",
      "     |  See also\n",
      "     |  --------\n",
      "     |  SVR\n",
      "     |      Support Vector Machine for Regression implemented using libsvm.\n",
      "     |  \n",
      "     |  LinearSVC\n",
      "     |      Scalable Linear Support Vector Machine for classification\n",
      "     |      implemented using liblinear. Check the See also section of\n",
      "     |      LinearSVC for more comparison element.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SVC\n",
      "     |      sklearn.svm.base.BaseSVC\n",
      "     |      abc.NewBase\n",
      "     |      sklearn.svm.base.BaseLibSVM\n",
      "     |      abc.NewBase\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.base.ClassifierMixin\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, C=1.0, kernel='rbf', degree=3, gamma='auto', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', random_state=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.svm.base.BaseSVC:\n",
      "     |  \n",
      "     |  decision_function(self, X)\n",
      "     |      Distance of the samples X to the separating hyperplane.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like, shape (n_samples, n_features)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X : array-like, shape (n_samples, n_classes * (n_classes-1) / 2)\n",
      "     |          Returns the decision function of the sample for each class\n",
      "     |          in the model.\n",
      "     |          If decision_function_shape='ovr', the shape is (n_samples,\n",
      "     |          n_classes)\n",
      "     |  \n",
      "     |  predict(self, X)\n",
      "     |      Perform classification on samples in X.\n",
      "     |      \n",
      "     |      For an one-class model, +1 or -1 is returned.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      "     |          For kernel=\"precomputed\", the expected shape of X is\n",
      "     |          [n_samples_test, n_samples_train]\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y_pred : array, shape (n_samples,)\n",
      "     |          Class labels for samples in X.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.svm.base.BaseSVC:\n",
      "     |  \n",
      "     |  predict_log_proba\n",
      "     |      Compute log probabilities of possible outcomes for samples in X.\n",
      "     |      \n",
      "     |      The model need to have probability information computed at training\n",
      "     |      time: fit with attribute `probability` set to True.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like, shape (n_samples, n_features)\n",
      "     |          For kernel=\"precomputed\", the expected shape of X is\n",
      "     |          [n_samples_test, n_samples_train]\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      T : array-like, shape (n_samples, n_classes)\n",
      "     |          Returns the log-probabilities of the sample for each class in\n",
      "     |          the model. The columns correspond to the classes in sorted\n",
      "     |          order, as they appear in the attribute `classes_`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability model is created using cross validation, so\n",
      "     |      the results can be slightly different than those obtained by\n",
      "     |      predict. Also, it will produce meaningless results on very small\n",
      "     |      datasets.\n",
      "     |  \n",
      "     |  predict_proba\n",
      "     |      Compute probabilities of possible outcomes for samples in X.\n",
      "     |      \n",
      "     |      The model need to have probability information computed at training\n",
      "     |      time: fit with attribute `probability` set to True.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like, shape (n_samples, n_features)\n",
      "     |          For kernel=\"precomputed\", the expected shape of X is\n",
      "     |          [n_samples_test, n_samples_train]\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      T : array-like, shape (n_samples, n_classes)\n",
      "     |          Returns the probability of the sample for each class in\n",
      "     |          the model. The columns correspond to the classes in sorted\n",
      "     |          order, as they appear in the attribute `classes_`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability model is created using cross validation, so\n",
      "     |      the results can be slightly different than those obtained by\n",
      "     |      predict. Also, it will produce meaningless results on very small\n",
      "     |      datasets.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.svm.base.BaseLibSVM:\n",
      "     |  \n",
      "     |  fit(self, X, y, sample_weight=None)\n",
      "     |      Fit the SVM model according to the given training data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      "     |          Training vectors, where n_samples is the number of samples\n",
      "     |          and n_features is the number of features.\n",
      "     |          For kernel=\"precomputed\", the expected shape of X is\n",
      "     |          (n_samples, n_samples).\n",
      "     |      \n",
      "     |      y : array-like, shape (n_samples,)\n",
      "     |          Target values (class labels in classification, real numbers in\n",
      "     |          regression)\n",
      "     |      \n",
      "     |      sample_weight : array-like, shape (n_samples,)\n",
      "     |          Per-sample weights. Rescale C per sample. Higher weights\n",
      "     |          force the classifier to put more emphasis on these points.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns self.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      ------\n",
      "     |      If X and y are not C-ordered and contiguous arrays of np.float64 and\n",
      "     |      X is not a scipy.sparse.csr_matrix, X and/or y may be copied.\n",
      "     |      \n",
      "     |      If X is a dense array, then the other methods will not support sparse\n",
      "     |      matrices as input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.svm.base.BaseLibSVM:\n",
      "     |  \n",
      "     |  coef_\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : boolean, optional\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : mapping of string to any\n",
      "     |          Parameter names mapped to their values.\n",
      "     |  \n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |      \n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as pipelines). The latter have parameters of the form\n",
      "     |      ``<component>__<parameter>`` so that it's possible to update each\n",
      "     |      component of a nested object.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      "     |  \n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Returns the mean accuracy on the given test data and labels.\n",
      "     |      \n",
      "     |      In multi-label classification, this is the subset accuracy\n",
      "     |      which is a harsh metric since you require for each sample that\n",
      "     |      each label set be correctly predicted.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like, shape = (n_samples, n_features)\n",
      "     |          Test samples.\n",
      "     |      \n",
      "     |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      "     |          True labels for X.\n",
      "     |      \n",
      "     |      sample_weight : array-like, shape = [n_samples], optional\n",
      "     |          Sample weights.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          Mean accuracy of self.predict(X) wrt. y.\n",
      "    \n",
      "    class SVR(sklearn.svm.base.BaseLibSVM, sklearn.base.RegressorMixin)\n",
      "     |  Epsilon-Support Vector Regression.\n",
      "     |  \n",
      "     |  The free parameters in the model are C and epsilon.\n",
      "     |  \n",
      "     |  The implementation is based on libsvm.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <svm_regression>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  C : float, optional (default=1.0)\n",
      "     |      Penalty parameter C of the error term.\n",
      "     |  \n",
      "     |  epsilon : float, optional (default=0.1)\n",
      "     |       Epsilon in the epsilon-SVR model. It specifies the epsilon-tube\n",
      "     |       within which no penalty is associated in the training loss function\n",
      "     |       with points predicted within a distance epsilon from the actual\n",
      "     |       value.\n",
      "     |  \n",
      "     |  kernel : string, optional (default='rbf')\n",
      "     |       Specifies the kernel type to be used in the algorithm.\n",
      "     |       It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
      "     |       a callable.\n",
      "     |       If none is given, 'rbf' will be used. If a callable is given it is\n",
      "     |       used to precompute the kernel matrix.\n",
      "     |  \n",
      "     |  degree : int, optional (default=3)\n",
      "     |      Degree of the polynomial kernel function ('poly').\n",
      "     |      Ignored by all other kernels.\n",
      "     |  \n",
      "     |  gamma : float, optional (default='auto')\n",
      "     |      Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
      "     |      If gamma is 'auto' then 1/n_features will be used instead.\n",
      "     |  \n",
      "     |  coef0 : float, optional (default=0.0)\n",
      "     |      Independent term in kernel function.\n",
      "     |      It is only significant in 'poly' and 'sigmoid'.\n",
      "     |  \n",
      "     |  shrinking : boolean, optional (default=True)\n",
      "     |      Whether to use the shrinking heuristic.\n",
      "     |  \n",
      "     |  tol : float, optional (default=1e-3)\n",
      "     |      Tolerance for stopping criterion.\n",
      "     |  \n",
      "     |  cache_size : float, optional\n",
      "     |      Specify the size of the kernel cache (in MB).\n",
      "     |  \n",
      "     |  verbose : bool, default: False\n",
      "     |      Enable verbose output. Note that this setting takes advantage of a\n",
      "     |      per-process runtime setting in libsvm that, if enabled, may not work\n",
      "     |      properly in a multithreaded context.\n",
      "     |  \n",
      "     |  max_iter : int, optional (default=-1)\n",
      "     |      Hard limit on iterations within solver, or -1 for no limit.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  support_ : array-like, shape = [n_SV]\n",
      "     |      Indices of support vectors.\n",
      "     |  \n",
      "     |  support_vectors_ : array-like, shape = [nSV, n_features]\n",
      "     |      Support vectors.\n",
      "     |  \n",
      "     |  dual_coef_ : array, shape = [1, n_SV]\n",
      "     |      Coefficients of the support vector in the decision function.\n",
      "     |  \n",
      "     |  coef_ : array, shape = [1, n_features]\n",
      "     |      Weights assigned to the features (coefficients in the primal\n",
      "     |      problem). This is only available in the case of a linear kernel.\n",
      "     |  \n",
      "     |      `coef_` is readonly property derived from `dual_coef_` and\n",
      "     |      `support_vectors_`.\n",
      "     |  \n",
      "     |  intercept_ : array, shape = [1]\n",
      "     |      Constants in decision function.\n",
      "     |  \n",
      "     |  sample_weight : array-like, shape = [n_samples]\n",
      "     |          Individual weights for each sample\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.svm import SVR\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> n_samples, n_features = 10, 5\n",
      "     |  >>> np.random.seed(0)\n",
      "     |  >>> y = np.random.randn(n_samples)\n",
      "     |  >>> X = np.random.randn(n_samples, n_features)\n",
      "     |  >>> clf = SVR(C=1.0, epsilon=0.2)\n",
      "     |  >>> clf.fit(X, y) #doctest: +NORMALIZE_WHITESPACE\n",
      "     |  SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.2, gamma='auto',\n",
      "     |      kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      "     |  \n",
      "     |  See also\n",
      "     |  --------\n",
      "     |  NuSVR\n",
      "     |      Support Vector Machine for regression implemented using libsvm\n",
      "     |      using a parameter to control the number of support vectors.\n",
      "     |  \n",
      "     |  LinearSVR\n",
      "     |      Scalable Linear Support Vector Machine for regression\n",
      "     |      implemented using liblinear.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SVR\n",
      "     |      sklearn.svm.base.BaseLibSVM\n",
      "     |      abc.NewBase\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.base.RegressorMixin\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, kernel='rbf', degree=3, gamma='auto', coef0=0.0, tol=0.001, C=1.0, epsilon=0.1, shrinking=True, cache_size=200, verbose=False, max_iter=-1)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.svm.base.BaseLibSVM:\n",
      "     |  \n",
      "     |  fit(self, X, y, sample_weight=None)\n",
      "     |      Fit the SVM model according to the given training data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      "     |          Training vectors, where n_samples is the number of samples\n",
      "     |          and n_features is the number of features.\n",
      "     |          For kernel=\"precomputed\", the expected shape of X is\n",
      "     |          (n_samples, n_samples).\n",
      "     |      \n",
      "     |      y : array-like, shape (n_samples,)\n",
      "     |          Target values (class labels in classification, real numbers in\n",
      "     |          regression)\n",
      "     |      \n",
      "     |      sample_weight : array-like, shape (n_samples,)\n",
      "     |          Per-sample weights. Rescale C per sample. Higher weights\n",
      "     |          force the classifier to put more emphasis on these points.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns self.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      ------\n",
      "     |      If X and y are not C-ordered and contiguous arrays of np.float64 and\n",
      "     |      X is not a scipy.sparse.csr_matrix, X and/or y may be copied.\n",
      "     |      \n",
      "     |      If X is a dense array, then the other methods will not support sparse\n",
      "     |      matrices as input.\n",
      "     |  \n",
      "     |  predict(self, X)\n",
      "     |      Perform regression on samples in X.\n",
      "     |      \n",
      "     |      For an one-class model, +1 (inlier) or -1 (outlier) is returned.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      "     |          For kernel=\"precomputed\", the expected shape of X is\n",
      "     |          (n_samples_test, n_samples_train).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y_pred : array, shape (n_samples,)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.svm.base.BaseLibSVM:\n",
      "     |  \n",
      "     |  coef_\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : boolean, optional\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : mapping of string to any\n",
      "     |          Parameter names mapped to their values.\n",
      "     |  \n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |      \n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as pipelines). The latter have parameters of the form\n",
      "     |      ``<component>__<parameter>`` so that it's possible to update each\n",
      "     |      component of a nested object.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.RegressorMixin:\n",
      "     |  \n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Returns the coefficient of determination R^2 of the prediction.\n",
      "     |      \n",
      "     |      The coefficient R^2 is defined as (1 - u/v), where u is the residual\n",
      "     |      sum of squares ((y_true - y_pred) ** 2).sum() and v is the total\n",
      "     |      sum of squares ((y_true - y_true.mean()) ** 2).sum().\n",
      "     |      The best possible score is 1.0 and it can be negative (because the\n",
      "     |      model can be arbitrarily worse). A constant model that always\n",
      "     |      predicts the expected value of y, disregarding the input features,\n",
      "     |      would get a R^2 score of 0.0.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like, shape = (n_samples, n_features)\n",
      "     |          Test samples.\n",
      "     |      \n",
      "     |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      "     |          True values for X.\n",
      "     |      \n",
      "     |      sample_weight : array-like, shape = [n_samples], optional\n",
      "     |          Sample weights.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          R^2 of self.predict(X) wrt. y.\n",
      "\n",
      "FUNCTIONS\n",
      "    l1_min_c(X, y, loss='squared_hinge', fit_intercept=True, intercept_scaling=1.0)\n",
      "        Return the lowest bound for C such that for C in (l1_min_C, infinity)\n",
      "        the model is guaranteed not to be empty. This applies to l1 penalized\n",
      "        classifiers, such as LinearSVC with penalty='l1' and\n",
      "        linear_model.LogisticRegression with penalty='l1'.\n",
      "        \n",
      "        This value is valid if class_weight parameter in fit() is not set.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        X : array-like or sparse matrix, shape = [n_samples, n_features]\n",
      "            Training vector, where n_samples in the number of samples and\n",
      "            n_features is the number of features.\n",
      "        \n",
      "        y : array, shape = [n_samples]\n",
      "            Target vector relative to X\n",
      "        \n",
      "        loss : {'squared_hinge', 'log'}, default 'squared_hinge'\n",
      "            Specifies the loss function.\n",
      "            With 'squared_hinge' it is the squared hinge loss (a.k.a. L2 loss).\n",
      "            With 'log' it is the loss of logistic regression models.\n",
      "            'l2' is accepted as an alias for 'squared_hinge', for backward\n",
      "            compatibility reasons, but should not be used in new code.\n",
      "        \n",
      "        fit_intercept : bool, default: True\n",
      "            Specifies if the intercept should be fitted by the model.\n",
      "            It must match the fit() method parameter.\n",
      "        \n",
      "        intercept_scaling : float, default: 1\n",
      "            when fit_intercept is True, instance vector x becomes\n",
      "            [x, intercept_scaling],\n",
      "            i.e. a \"synthetic\" feature with constant value equals to\n",
      "            intercept_scaling is appended to the instance vector.\n",
      "            It must match the fit() method parameter.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        l1_min_c : float\n",
      "            minimum value for C\n",
      "\n",
      "DATA\n",
      "    __all__ = ['LinearSVC', 'LinearSVR', 'NuSVC', 'NuSVR', 'OneClassSVM', ...\n",
      "\n",
      "FILE\n",
      "    /usr/local/lib/python3.6/site-packages/sklearn/svm/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "help(svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature vector for each gene (node) from PCNet\n",
    "all_genes = pcnet.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-15-5fbd0ff50e77>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-5fbd0ff50e77>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    for gene in all_genes:\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "for gene in all_genes:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_adj = pd.DataFrame(nx.adjacency_matrix(pcnet).toarray())\n",
    "pc_adj_mat = pc_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_adj.columns = pcnet.nodes\n",
    "pc_adj.index = pcnet.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UBE2Q1</th>\n",
       "      <th>RNF14</th>\n",
       "      <th>UBE2Q2</th>\n",
       "      <th>TMCO1</th>\n",
       "      <th>UBAC1</th>\n",
       "      <th>WWP1</th>\n",
       "      <th>ZNF706</th>\n",
       "      <th>MIB2</th>\n",
       "      <th>RNF114</th>\n",
       "      <th>RNF115</th>\n",
       "      <th>...</th>\n",
       "      <th>TMEM26</th>\n",
       "      <th>RAD51AP2</th>\n",
       "      <th>AC010422.6</th>\n",
       "      <th>PLEKHA8P1</th>\n",
       "      <th>CD300LD</th>\n",
       "      <th>BAGE4</th>\n",
       "      <th>FAM181B</th>\n",
       "      <th>IGFL3</th>\n",
       "      <th>BAT4</th>\n",
       "      <th>TPT1P8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UBE2Q1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RNF14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UBE2Q2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TMCO1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UBAC1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 19781 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        UBE2Q1  RNF14  UBE2Q2  TMCO1  UBAC1  WWP1  ZNF706  MIB2  RNF114  \\\n",
       "UBE2Q1       0      1       1      1      1     1       1     1       1   \n",
       "RNF14        1      0       1      1      0     1       0     0       0   \n",
       "UBE2Q2       1      1       0      0      1     1       1     1       1   \n",
       "TMCO1        1      1       0      0      0     0       0     0       0   \n",
       "UBAC1        1      0       1      0      0     0       0     0       0   \n",
       "\n",
       "        RNF115   ...    TMEM26  RAD51AP2  AC010422.6  PLEKHA8P1  CD300LD  \\\n",
       "UBE2Q1       1   ...         0         0           0          0        0   \n",
       "RNF14        0   ...         0         0           0          0        0   \n",
       "UBE2Q2       1   ...         0         0           0          0        0   \n",
       "TMCO1        0   ...         0         0           0          0        0   \n",
       "UBAC1        0   ...         0         0           0          0        0   \n",
       "\n",
       "        BAGE4  FAM181B  IGFL3  BAT4  TPT1P8  \n",
       "UBE2Q1      0        0      0     0       0  \n",
       "RNF14       0        0      0     0       0  \n",
       "UBE2Q2      0        0      0     0       0  \n",
       "TMCO1       0        0      0     0       0  \n",
       "UBAC1       0        0      0     0       0  \n",
       "\n",
       "[5 rows x 19781 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc_adj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SpectralClustering(eigen_solver = \"amg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/cluster/spectral.py:442: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n",
      "  warnings.warn(\"The spectral clustering API has changed. ``fit``\"\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/manifold/spectral_embedding_.py:234: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-9149f3581871>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpc_adj_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_predict\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;31m# non-optimized default implementation; override when a better\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;31m# method is possible for a given clustering algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/cluster/spectral.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    470\u001b[0m                                            \u001b[0mn_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m                                            \u001b[0meigen_tol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meigen_tol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m                                            assign_labels=self.assign_labels)\n\u001b[0m\u001b[1;32m    473\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/cluster/spectral.py\u001b[0m in \u001b[0;36mspectral_clustering\u001b[0;34m(affinity, n_clusters, n_components, eigen_solver, random_state, n_init, eigen_tol, assign_labels)\u001b[0m\n\u001b[1;32m    260\u001b[0m                               \u001b[0meigen_solver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meigen_solver\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                               \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                               eigen_tol=eigen_tol, drop_first=False)\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0massign_labels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'kmeans'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/manifold/spectral_embedding_.py\u001b[0m in \u001b[0;36mspectral_embedding\u001b[0;34m(adjacency, n_components, eigen_solver, random_state, eigen_tol, norm_laplacian, drop_first)\u001b[0m\n\u001b[1;32m    268\u001b[0m             lambdas, diffusion_map = eigsh(laplacian, k=n_components,\n\u001b[1;32m    269\u001b[0m                                            \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhich\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'LM'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m                                            tol=eigen_tol, v0=v0)\n\u001b[0m\u001b[1;32m    271\u001b[0m             \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiffusion_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen/arpack/arpack.py\u001b[0m in \u001b[0;36meigsh\u001b[0;34m(A, k, M, sigma, which, v0, ncv, maxiter, tol, return_eigenvectors, Minv, OPinv, mode)\u001b[0m\n\u001b[1;32m   1649\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_ARPACK_LOCK\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverged\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1651\u001b[0;31m             \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1653\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_eigenvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen/arpack/arpack.py\u001b[0m in \u001b[0;36miterate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m                 \u001b[0mBxslice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipntr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipntr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myslice\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBxslice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mido\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myslice\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxslice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/interface.py\u001b[0m in \u001b[0;36mmatvec\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dimension mismatch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen/arpack/arpack.py\u001b[0m in \u001b[0;36m_matvec\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_matvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlu_solve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM_lu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/scipy/linalg/decomp_lu.py\u001b[0m in \u001b[0;36mlu_solve\u001b[0;34m(lu_and_piv, b, trans, overwrite_b, check_finite)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mgetrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_lapack_funcs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'getrs'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverwrite_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sc.fit_predict(pc_adj_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(pc_adj_mat, y = gene_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([1,0,1,0,1,0,1,1,1,0]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(pd.DataFrame(pclap.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5099.19036741,  659.95082241])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = pca.fit_transform(pd.DataFrame(pclap.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19781, 2)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fb8dd8fbf28>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(proj[:, 0], proj[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "pclap_df = pd.DataFrame(pclap.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19771</th>\n",
       "      <th>19772</th>\n",
       "      <th>19773</th>\n",
       "      <th>19774</th>\n",
       "      <th>19775</th>\n",
       "      <th>19776</th>\n",
       "      <th>19777</th>\n",
       "      <th>19778</th>\n",
       "      <th>19779</th>\n",
       "      <th>19780</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>364</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>603</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>634</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 19781 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9      \\\n",
       "0    364     -1     -1     -1     -1     -1     -1     -1     -1     -1   \n",
       "1     -1    603     -1     -1      0     -1      0      0      0      0   \n",
       "2     -1     -1    400      0     -1     -1     -1     -1     -1     -1   \n",
       "3     -1     -1      0    634      0      0      0      0      0      0   \n",
       "4     -1      0     -1      0    415      0      0      0      0      0   \n",
       "\n",
       "   ...    19771  19772  19773  19774  19775  19776  19777  19778  19779  19780  \n",
       "0  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "1  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "2  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "3  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "4  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 19781 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pclap_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1.00424999e+04, 9.83019865e-02])]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[_ for _ in proj if _[0] > 3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
